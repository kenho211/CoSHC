{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L16UMaFg6hUn"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo51z1qY3mwg",
        "outputId": "dcd3a65f-e9f5-4c1c-9e11-de6d286953f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhxYqtRb8wAN",
        "outputId": "302d355c-fcc0-46ce-aa69-12607474e818"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/CoSHC/data/python.zip\n",
            "   creating: /content/data/python/\n",
            "   creating: /content/data/python/final/\n",
            "   creating: /content/data/python/final/jsonl/\n",
            "   creating: /content/data/python/final/jsonl/train/\n",
            "  inflating: /content/data/python/final/jsonl/train/python_train_9.jsonl.gz  \n",
            "  inflating: /content/data/python/final/jsonl/train/python_train_12.jsonl.gz  \n",
            "  inflating: /content/data/python/final/jsonl/train/python_train_10.jsonl.gz  \n",
            "  inflating: /content/data/python/final/jsonl/train/python_train_0.jsonl.gz  \n",
            "  inflating: /content/data/python/final/jsonl/train/python_train_6.jsonl.gz  \n",
            "  inflating: /content/data/python/final/jsonl/train/python_train_2.jsonl.gz  \n",
            "  inflating: /content/data/python/final/jsonl/train/python_train_4.jsonl.gz  \n",
            "  inflating: /content/data/python/final/jsonl/train/python_train_8.jsonl.gz  \n",
            "  inflating: /content/data/python/final/jsonl/train/python_train_11.jsonl.gz  \n",
            "  inflating: /content/data/python/final/jsonl/train/python_train_5.jsonl.gz  \n",
            "  inflating: /content/data/python/final/jsonl/train/python_train_13.jsonl.gz  \n",
            "  inflating: /content/data/python/final/jsonl/train/python_train_3.jsonl.gz  \n",
            "  inflating: /content/data/python/final/jsonl/train/python_train_1.jsonl.gz  \n",
            "  inflating: /content/data/python/final/jsonl/train/python_train_7.jsonl.gz  \n",
            "   creating: /content/data/python/final/jsonl/test/\n",
            "  inflating: /content/data/python/final/jsonl/test/python_test_0.jsonl.gz  \n",
            "   creating: /content/data/python/final/jsonl/valid/\n",
            "  inflating: /content/data/python/final/jsonl/valid/python_valid_0.jsonl.gz  \n",
            "  inflating: /content/data/python_dedupe_definitions_v2.pkl  \n",
            "  inflating: /content/data/python_licenses.pkl  \n",
            "Archive:  /content/drive/MyDrive/CoSHC/data/java.zip\n",
            "   creating: /content/data/java/\n",
            "   creating: /content/data/java/final/\n",
            "   creating: /content/data/java/final/jsonl/\n",
            "   creating: /content/data/java/final/jsonl/train/\n",
            "  inflating: /content/data/java/final/jsonl/train/java_train_12.jsonl.gz  \n",
            "  inflating: /content/data/java/final/jsonl/train/java_train_9.jsonl.gz  \n",
            "  inflating: /content/data/java/final/jsonl/train/java_train_3.jsonl.gz  \n",
            "  inflating: /content/data/java/final/jsonl/train/java_train_5.jsonl.gz  \n",
            "  inflating: /content/data/java/final/jsonl/train/java_train_7.jsonl.gz  \n",
            "  inflating: /content/data/java/final/jsonl/train/java_train_1.jsonl.gz  \n",
            "  inflating: /content/data/java/final/jsonl/train/java_train_10.jsonl.gz  \n",
            "  inflating: /content/data/java/final/jsonl/train/java_train_14.jsonl.gz  \n",
            "  inflating: /content/data/java/final/jsonl/train/java_train_0.jsonl.gz  \n",
            "  inflating: /content/data/java/final/jsonl/train/java_train_6.jsonl.gz  \n",
            "  inflating: /content/data/java/final/jsonl/train/java_train_8.jsonl.gz  \n",
            "  inflating: /content/data/java/final/jsonl/train/java_train_15.jsonl.gz  \n",
            "  inflating: /content/data/java/final/jsonl/train/java_train_2.jsonl.gz  \n",
            "  inflating: /content/data/java/final/jsonl/train/java_train_4.jsonl.gz  \n",
            "  inflating: /content/data/java/final/jsonl/train/java_train_13.jsonl.gz  \n",
            "  inflating: /content/data/java/final/jsonl/train/java_train_11.jsonl.gz  \n",
            "   creating: /content/data/java/final/jsonl/test/\n",
            "  inflating: /content/data/java/final/jsonl/test/java_test_0.jsonl.gz  \n",
            "   creating: /content/data/java/final/jsonl/valid/\n",
            "  inflating: /content/data/java/final/jsonl/valid/java_valid_0.jsonl.gz  \n",
            "  inflating: /content/data/java_dedupe_definitions_v2.pkl  \n",
            "  inflating: /content/data/java_licenses.pkl  \n"
          ]
        }
      ],
      "source": [
        "!mkdir /content/data\n",
        "!unzip /content/drive/MyDrive/CoSHC/data/python.zip -d /content/data\n",
        "!unzip /content/drive/MyDrive/CoSHC/data/java.zip -d /content/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzpfRozu9mx0"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/CoSHC/data/python /content/data/\n",
        "!cp -r /content/drive/MyDrive/CoSHC/data/java /content/data/\n",
        "!cp /content/drive/MyDrive/CoSHC/data/preprocess.py /content/data/preprocess.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Wfc5qo19vJj",
        "outputId": "7ccb9e4b-2abc-4dff-d012-0aa24823e9b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/data\n",
            "java\n",
            "gzip: java/final/jsonl/valid/java_valid_0.jsonl.gz: No such file or directory\n",
            "gzip: java/final/jsonl/test/java_test_0.jsonl.gz: No such file or directory\n",
            "python\n",
            "gzip: python/final/jsonl/valid/python_valid_0.jsonl.gz: No such file or directory\n",
            "gzip: python/final/jsonl/test/python_test_0.jsonl.gz: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "%cd /content/data\n",
        "!python preprocess.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nfhj-UYIzjya"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/NVIDIA/apex\n",
        "# %cd /content/apex\n",
        "\n",
        "# !pip install -v --disable-pip-version-check --no-build-isolation --no-cache-dir ./\n",
        "# if pip >= 23.1 (ref: https://pip.pypa.io/en/stable/news/#v23-1) which supports multiple `--config-settings` with the same key...\n",
        "# !pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation --config-settings \"--build-option=--cpp_ext\" --config-settings \"--build-option=--cuda_ext\" ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Jr9volNv17tZ",
        "outputId": "71d57007-7da1-4d79-f74e-770406d13a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (4.25.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upoazzBg2He1",
        "outputId": "75170171-dc05-46c8-ba75-af6a35e1a1f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'CoSHC'...\n",
            "remote: Enumerating objects: 80, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 80 (delta 42), reused 56 (delta 21), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (80/80), 36.25 KiB | 18.13 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n",
            "/content/CoSHC/CodeBERT\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "GITHUB_PAT = userdata.get('GITHUB_PAT')\n",
        "GITHUB_USERNAME = userdata.get('GITHUB_USERNAME')\n",
        "REPO_NAME = \"CoSHC\"\n",
        "\n",
        "%cd /content\n",
        "!git clone https://$GITHUB_USERNAME:$GITHUB_PAT@github.com/$GITHUB_USERNAME/$REPO_NAME\n",
        "%cd /content/$REPO_NAME/CodeBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "brWg2BExLVj1",
        "outputId": "dddd0841-e4ff-493e-a9ea-18afeeb099b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-03-18 16:47:54.770109: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-03-18 16:47:54.786811: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742316474.808615    4817 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742316474.815184    4817 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-18 16:47:54.837544: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "03/18/2025 16:47:57 - INFO - __main__ -   device: cuda, n_gpu: 1\n",
            "config.json: 100% 498/498 [00:00<00:00, 3.50MB/s]\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 226kB/s]\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 12.2MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 1.05MB/s]\n",
            "special_tokens_map.json: 100% 150/150 [00:00<00:00, 1.31MB/s]\n",
            "pytorch_model.bin: 100% 499M/499M [00:02<00:00, 229MB/s]\n",
            "03/18/2025 16:48:08 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='/content/data/python/train.jsonl', output_dir='/content/drive/MyDrive/CoSHC/CodeBERT/models/python', eval_data_file='/content/data/python/valid.jsonl', test_data_file='/content/data/python/test.jsonl', codebase_file='/content/data/python/codebase.jsonl', model_name_or_path='microsoft/codebert-base', config_name='microsoft/codebert-base', tokenizer_name='microsoft/codebert-base', nl_length=128, code_length=256, do_train=True, do_eval=False, do_test=False, train_batch_size=32, eval_batch_size=64, learning_rate=1e-05, max_grad_norm=1.0, num_train_epochs=10, seed=123456, n_gpu=1, device=device(type='cuda'))\n",
            "model.safetensors: 100% 499M/499M [00:14<00:00, 35.5MB/s]\n",
            "03/18/2025 16:52:46 - INFO - __main__ -   *** Example ***\n",
            "03/18/2025 16:52:46 - INFO - __main__ -   idx: 0\n",
            "03/18/2025 16:52:46 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_split', '_', 'ph', 'yl', 'ogen', 'y', '_(', '_p', '_,', '_level', '_=', '_\"', 's', '\"', '_)', '_:', '_level', '_=', '_level', '_+', '_\"', '__', '\"', '_result', '_=', '_p', '_.', '_split', '_(', '_level', '_)', '_return', '_result', '_[', '_0', '_]', '_+', '_level', '_+', '_result', '_[', '_1', '_]', '_.', '_split', '_(', '_\"', ';\"', '_)', '_[', '_0', '_]', '</s>']\n",
            "03/18/2025 16:52:46 - INFO - __main__ -   code_ids: 0 9232 3462 1215 3792 4360 11575 219 36 181 2156 672 5457 22 29 113 4839 4832 672 5457 672 2055 22 30529 113 898 5457 181 479 3462 36 672 4839 671 898 646 321 27779 2055 672 2055 898 646 112 27779 479 3462 36 22 42777 4839 646 321 27779 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "03/18/2025 16:52:46 - INFO - __main__ -   nl_tokens: ['<s>', 'Return', '_either', '_the', '_full', '_or', '_trunc', 'ated', '_version', '_of', '_a', '_Q', 'I', 'IME', '_-', '_formatted', '_tax', 'onomy', '_string', '_.', '</s>']\n",
            "03/18/2025 16:52:46 - INFO - __main__ -   nl_ids: 0 42555 1169 5 455 50 43064 1070 1732 9 10 1209 100 28417 111 46625 629 38217 6755 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "03/18/2025 16:52:46 - INFO - __main__ -   *** Example ***\n",
            "03/18/2025 16:52:46 - INFO - __main__ -   idx: 1\n",
            "03/18/2025 16:52:46 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_ensure', '_', 'dir', '_(', '_d', '_)', '_:', '_if', '_not', '_os', '_.', '_path', '_.', '_exists', '_(', '_d', '_)', '_:', '_try', '_:', '_os', '_.', '_m', 'aked', 'irs', '_(', '_d', '_)', '_except', '_O', 'SE', 'r', 'ror', '_as', '_o', 'e', '_:', '_#', '_should', '_not', '_happen', '_with', '_os', '.', 'm', 'aked', 'irs', '_#', '_EN', 'O', 'ENT', ':', '_No', '_such', '_file', '_or', '_directory', '_if', '_os', '_.', '_err', 'no', '_==', '_err', 'no', '_.', '_EN', 'O', 'ENT', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_\"\"\"', 'One', '_or', '_more', '_directories', '_in', '_the', '_path', '_({', '})', '_do', '_not', '_exist', '.', '_If', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_you', '_are', '_specifying', '_a', '_new', '_directory', '_for', '_output', ',', '_please', '_ensure', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_all', '_other', '_directories', '_in', '_the', '_path', '_currently', '_exist', '.\"', '\"\"', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_)', '_else', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_\"\"\"', 'An', '_error', '_occurred', '_trying', '_to', '_create', '_the', '_output', '_directory', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_({', '})', '_with', '_message', ':', '_{}', '\"\"\"', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_,', '_o', 'e', '_.', '_stre', 'r', 'ror', '_)', '</s>']\n",
            "03/18/2025 16:52:46 - INFO - __main__ -   code_ids: 0 9232 1306 1215 41292 36 385 4839 4832 114 45 11988 479 2718 479 8785 36 385 4839 4832 860 4832 11988 479 475 8435 21098 36 385 4839 4682 384 3388 338 21929 25 1021 242 4832 849 197 45 1369 19 11988 4 119 8435 21098 849 13245 673 5382 35 440 215 2870 50 31826 114 11988 479 22379 2362 45994 22379 2362 479 13245 673 5382 4832 49049 5457 11901 16134 36 49434 3762 50 55 44472 11 5 2718 49698 49424 109 45 5152 4 318 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 47 32 39140 10 92 31826 13 4195 6 2540 1306 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 70 97 44472 11 5 2718 855 5152 72 48149 4839 671 49049 479 7390 36 385 4839 1493 4832 49049 5457 11901 16134 36 49434 4688 5849 2756 667 7 1045 5 4195 31826 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 49698 49424 19 1579 35 49153 49849 4839 671 49049 479 7390 36 385 2156 1021 242 479 22246 338 21929 4839 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "03/18/2025 16:52:46 - INFO - __main__ -   nl_tokens: ['<s>', 'Check', '_to', '_make', '_sure', '_the', '_supplied', '_directory', '_path', '_does', '_not', '_exist', '_if', '_so', '_create', '_it', '_.', '_The', '_method', '_catches', '_O', 'SE', 'r', 'ror', '_exceptions', '_and', '_returns', '_a', '_descriptive', '_message', '_instead', '_of', '_re', '_-', '_raising', '_the', '_error', '_.', '</s>']\n",
            "03/18/2025 16:52:46 - INFO - __main__ -   nl_ids: 0 26615 7 146 686 5 12359 31826 2718 473 45 5152 114 98 1045 24 479 20 5448 8758 384 3388 338 21929 18286 8 2886 10 42690 1579 1386 9 769 111 3282 5 5849 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "03/18/2025 16:52:46 - INFO - __main__ -   *** Example ***\n",
            "03/18/2025 16:52:46 - INFO - __main__ -   idx: 2\n",
            "03/18/2025 16:52:46 - INFO - __main__ -   code_tokens: ['<s>', 'def', '_file', '_', 'handle', '_(', '_fn', 'h', '_,', '_mode', '_=', '_\"', 'r', 'U', '\"', '_)', '_:', '_handle', '_=', '_None', '_if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_file', '_)', '_:', '_if', '_fn', 'h', '_.', '_closed', '_:', '_raise', '_Value', 'Error', '_(', '_\"', 'Input', '_file', '_is', '_closed', '.\"', '_)', '_handle', '_=', '_fn', 'h', '_el', 'if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_str', '_)', '_:', '_handle', '_=', '_open', '_(', '_fn', 'h', '_,', '_mode', '_)', '_return', '_handle', '</s>']\n",
            "03/18/2025 16:52:46 - INFO - __main__ -   code_ids: 0 9232 2870 1215 26628 36 48930 298 2156 5745 5457 22 338 791 113 4839 4832 3679 5457 9291 114 16 48768 36 48930 298 2156 2870 4839 4832 114 48930 298 479 1367 4832 1693 11714 30192 36 22 48214 2870 16 1367 72 4839 3679 5457 48930 298 1615 1594 16 48768 36 48930 298 2156 7031 4839 4832 3679 5457 490 36 48930 298 2156 5745 4839 671 3679 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "03/18/2025 16:52:46 - INFO - __main__ -   nl_tokens: ['<s>', 'T', 'akes', '_either', '_a', '_file', '_path', '_or', '_an', '_open', '_file', '_handle', '_checks', '_validity', '_and', '_returns', '_an', '_open', '_file', '_handle', '_or', '_raises', '_an', '_appropriate', '_Exception', '_.', '</s>']\n",
            "03/18/2025 16:52:46 - INFO - __main__ -   nl_ids: 0 565 5556 1169 10 2870 2718 50 41 490 2870 3679 6240 25295 8 2886 41 490 2870 3679 50 7700 41 3901 47617 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "03/18/2025 16:52:47 - INFO - __main__ -   ***** Running training *****\n",
            "03/18/2025 16:52:47 - INFO - __main__ -     Num examples = 251820\n",
            "03/18/2025 16:52:47 - INFO - __main__ -     Num Epochs = 10\n",
            "03/18/2025 16:52:47 - INFO - __main__ -     Instantaneous batch size per GPU = 32\n",
            "03/18/2025 16:52:47 - INFO - __main__ -     Total train batch size  = 32\n",
            "03/18/2025 16:52:47 - INFO - __main__ -     Total optimization steps = 78700\n",
            "03/18/2025 16:53:33 - INFO - __main__ -   epoch 0 step 100 loss 3.57131\n",
            "03/18/2025 16:54:17 - INFO - __main__ -   epoch 0 step 200 loss 0.46807\n",
            "03/18/2025 16:55:01 - INFO - __main__ -   epoch 0 step 300 loss 0.31657\n",
            "03/18/2025 16:55:45 - INFO - __main__ -   epoch 0 step 400 loss 0.24049\n",
            "03/18/2025 16:56:29 - INFO - __main__ -   epoch 0 step 500 loss 0.22895\n",
            "03/18/2025 16:57:14 - INFO - __main__ -   epoch 0 step 600 loss 0.21732\n",
            "03/18/2025 16:57:58 - INFO - __main__ -   epoch 0 step 700 loss 0.19731\n",
            "03/18/2025 16:58:42 - INFO - __main__ -   epoch 0 step 800 loss 0.20602\n",
            "03/18/2025 16:59:26 - INFO - __main__ -   epoch 0 step 900 loss 0.1673\n",
            "03/18/2025 17:00:10 - INFO - __main__ -   epoch 0 step 1000 loss 0.16888\n",
            "03/18/2025 17:00:54 - INFO - __main__ -   epoch 0 step 1100 loss 0.18188\n",
            "03/18/2025 17:01:39 - INFO - __main__ -   epoch 0 step 1200 loss 0.16014\n",
            "03/18/2025 17:02:23 - INFO - __main__ -   epoch 0 step 1300 loss 0.1675\n",
            "03/18/2025 17:03:07 - INFO - __main__ -   epoch 0 step 1400 loss 0.15188\n",
            "03/18/2025 17:03:51 - INFO - __main__ -   epoch 0 step 1500 loss 0.18291\n",
            "03/18/2025 17:04:35 - INFO - __main__ -   epoch 0 step 1600 loss 0.14994\n",
            "03/18/2025 17:05:19 - INFO - __main__ -   epoch 0 step 1700 loss 0.15349\n",
            "03/18/2025 17:06:04 - INFO - __main__ -   epoch 0 step 1800 loss 0.15368\n",
            "03/18/2025 17:06:48 - INFO - __main__ -   epoch 0 step 1900 loss 0.15078\n",
            "03/18/2025 17:07:32 - INFO - __main__ -   epoch 0 step 2000 loss 0.13131\n",
            "03/18/2025 17:08:16 - INFO - __main__ -   epoch 0 step 2100 loss 0.15137\n",
            "03/18/2025 17:09:00 - INFO - __main__ -   epoch 0 step 2200 loss 0.1491\n",
            "03/18/2025 17:09:44 - INFO - __main__ -   epoch 0 step 2300 loss 0.14667\n",
            "03/18/2025 17:10:29 - INFO - __main__ -   epoch 0 step 2400 loss 0.11693\n",
            "03/18/2025 17:11:13 - INFO - __main__ -   epoch 0 step 2500 loss 0.15942\n",
            "03/18/2025 17:11:57 - INFO - __main__ -   epoch 0 step 2600 loss 0.13985\n",
            "03/18/2025 17:12:41 - INFO - __main__ -   epoch 0 step 2700 loss 0.13373\n",
            "03/18/2025 17:13:25 - INFO - __main__ -   epoch 0 step 2800 loss 0.12558\n",
            "03/18/2025 17:14:10 - INFO - __main__ -   epoch 0 step 2900 loss 0.12473\n",
            "03/18/2025 17:14:54 - INFO - __main__ -   epoch 0 step 3000 loss 0.15733\n",
            "03/18/2025 17:15:38 - INFO - __main__ -   epoch 0 step 3100 loss 0.13688\n",
            "03/18/2025 17:16:22 - INFO - __main__ -   epoch 0 step 3200 loss 0.13333\n",
            "03/18/2025 17:17:06 - INFO - __main__ -   epoch 0 step 3300 loss 0.13659\n",
            "03/18/2025 17:17:51 - INFO - __main__ -   epoch 0 step 3400 loss 0.13775\n",
            "03/18/2025 17:18:35 - INFO - __main__ -   epoch 0 step 3500 loss 0.11398\n",
            "03/18/2025 17:19:19 - INFO - __main__ -   epoch 0 step 3600 loss 0.11483\n",
            "03/18/2025 17:20:03 - INFO - __main__ -   epoch 0 step 3700 loss 0.11417\n",
            "03/18/2025 17:20:49 - INFO - __main__ -   epoch 0 step 3800 loss 0.13261\n",
            "03/18/2025 17:21:34 - INFO - __main__ -   epoch 0 step 3900 loss 0.13429\n",
            "03/18/2025 17:22:18 - INFO - __main__ -   epoch 0 step 4000 loss 0.1268\n",
            "03/18/2025 17:23:02 - INFO - __main__ -   epoch 0 step 4100 loss 0.09866\n",
            "03/18/2025 17:23:46 - INFO - __main__ -   epoch 0 step 4200 loss 0.13617\n",
            "03/18/2025 17:24:30 - INFO - __main__ -   epoch 0 step 4300 loss 0.12842\n",
            "03/18/2025 17:25:14 - INFO - __main__ -   epoch 0 step 4400 loss 0.12455\n",
            "03/18/2025 17:25:59 - INFO - __main__ -   epoch 0 step 4500 loss 0.13826\n",
            "03/18/2025 17:26:43 - INFO - __main__ -   epoch 0 step 4600 loss 0.12311\n",
            "03/18/2025 17:27:27 - INFO - __main__ -   epoch 0 step 4700 loss 0.12222\n",
            "03/18/2025 17:28:11 - INFO - __main__ -   epoch 0 step 4800 loss 0.10038\n",
            "03/18/2025 17:28:55 - INFO - __main__ -   epoch 0 step 4900 loss 0.12333\n",
            "03/18/2025 17:29:39 - INFO - __main__ -   epoch 0 step 5000 loss 0.10357\n",
            "03/18/2025 17:30:24 - INFO - __main__ -   epoch 0 step 5100 loss 0.11788\n",
            "03/18/2025 17:31:08 - INFO - __main__ -   epoch 0 step 5200 loss 0.13831\n",
            "03/18/2025 17:31:52 - INFO - __main__ -   epoch 0 step 5300 loss 0.10128\n",
            "03/18/2025 17:32:36 - INFO - __main__ -   epoch 0 step 5400 loss 0.10125\n",
            "03/18/2025 17:33:20 - INFO - __main__ -   epoch 0 step 5500 loss 0.12614\n",
            "03/18/2025 17:34:04 - INFO - __main__ -   epoch 0 step 5600 loss 0.11468\n",
            "03/18/2025 17:34:49 - INFO - __main__ -   epoch 0 step 5700 loss 0.11401\n",
            "03/18/2025 17:35:33 - INFO - __main__ -   epoch 0 step 5800 loss 0.11707\n",
            "03/18/2025 17:36:17 - INFO - __main__ -   epoch 0 step 5900 loss 0.12007\n",
            "03/18/2025 17:37:01 - INFO - __main__ -   epoch 0 step 6000 loss 0.11678\n",
            "03/18/2025 17:37:45 - INFO - __main__ -   epoch 0 step 6100 loss 0.11213\n",
            "03/18/2025 17:38:29 - INFO - __main__ -   epoch 0 step 6200 loss 0.09884\n",
            "03/18/2025 17:39:14 - INFO - __main__ -   epoch 0 step 6300 loss 0.10903\n",
            "03/18/2025 17:39:58 - INFO - __main__ -   epoch 0 step 6400 loss 0.12102\n",
            "03/18/2025 17:40:42 - INFO - __main__ -   epoch 0 step 6500 loss 0.08052\n",
            "03/18/2025 17:41:26 - INFO - __main__ -   epoch 0 step 6600 loss 0.11818\n",
            "03/18/2025 17:42:10 - INFO - __main__ -   epoch 0 step 6700 loss 0.1104\n",
            "03/18/2025 17:42:55 - INFO - __main__ -   epoch 0 step 6800 loss 0.09494\n",
            "03/18/2025 17:43:39 - INFO - __main__ -   epoch 0 step 6900 loss 0.11046\n",
            "03/18/2025 17:44:23 - INFO - __main__ -   epoch 0 step 7000 loss 0.10824\n",
            "03/18/2025 17:45:07 - INFO - __main__ -   epoch 0 step 7100 loss 0.12506\n",
            "03/18/2025 17:45:51 - INFO - __main__ -   epoch 0 step 7200 loss 0.12765\n",
            "03/18/2025 17:46:35 - INFO - __main__ -   epoch 0 step 7300 loss 0.10172\n",
            "03/18/2025 17:47:19 - INFO - __main__ -   epoch 0 step 7400 loss 0.1005\n",
            "03/18/2025 17:48:04 - INFO - __main__ -   epoch 0 step 7500 loss 0.09437\n",
            "03/18/2025 17:48:48 - INFO - __main__ -   epoch 0 step 7600 loss 0.09353\n",
            "03/18/2025 17:49:32 - INFO - __main__ -   epoch 0 step 7700 loss 0.10307\n",
            "03/18/2025 17:50:16 - INFO - __main__ -   epoch 0 step 7800 loss 0.11541\n",
            "03/18/2025 17:51:35 - INFO - __main__ -   ***** Running evaluation *****\n",
            "03/18/2025 17:51:35 - INFO - __main__ -     Num queries = 13914\n",
            "03/18/2025 17:51:35 - INFO - __main__ -     Num codes = 43827\n",
            "03/18/2025 17:51:35 - INFO - __main__ -     Batch size = 64\n",
            "03/18/2025 17:54:10 - INFO - __main__ -     Success@1 = 0.0\n",
            "03/18/2025 17:54:10 - INFO - __main__ -     Success@5 = 0.0001\n",
            "03/18/2025 17:54:10 - INFO - __main__ -     Success@10 = 0.0004\n",
            "03/18/2025 17:54:10 - INFO - __main__ -     MRR = 0.5875\n",
            "03/18/2025 17:54:10 - INFO - __main__ -     ********************\n",
            "03/18/2025 17:54:10 - INFO - __main__ -     Best mrr:0.5875\n",
            "03/18/2025 17:54:10 - INFO - __main__ -     ********************\n",
            "03/18/2025 17:54:14 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/CoSHC/CodeBERT/models/python/checkpoint-best-mrr/model.bin\n",
            "03/18/2025 17:54:58 - INFO - __main__ -   epoch 1 step 100 loss 0.08207\n",
            "03/18/2025 17:55:42 - INFO - __main__ -   epoch 1 step 200 loss 0.09262\n",
            "03/18/2025 17:56:26 - INFO - __main__ -   epoch 1 step 300 loss 0.0987\n",
            "03/18/2025 17:57:10 - INFO - __main__ -   epoch 1 step 400 loss 0.07723\n",
            "03/18/2025 17:57:55 - INFO - __main__ -   epoch 1 step 500 loss 0.09856\n",
            "03/18/2025 17:58:39 - INFO - __main__ -   epoch 1 step 600 loss 0.05726\n",
            "03/18/2025 17:59:23 - INFO - __main__ -   epoch 1 step 700 loss 0.09092\n",
            "03/18/2025 18:00:07 - INFO - __main__ -   epoch 1 step 800 loss 0.05719\n",
            "03/18/2025 18:00:51 - INFO - __main__ -   epoch 1 step 900 loss 0.06939\n",
            "03/18/2025 18:01:35 - INFO - __main__ -   epoch 1 step 1000 loss 0.0769\n",
            "03/18/2025 18:02:20 - INFO - __main__ -   epoch 1 step 1100 loss 0.08598\n",
            "03/18/2025 18:03:04 - INFO - __main__ -   epoch 1 step 1200 loss 0.08316\n",
            "03/18/2025 18:03:48 - INFO - __main__ -   epoch 1 step 1300 loss 0.0849\n",
            "03/18/2025 18:04:32 - INFO - __main__ -   epoch 1 step 1400 loss 0.08681\n",
            "03/18/2025 18:05:16 - INFO - __main__ -   epoch 1 step 1500 loss 0.06955\n",
            "03/18/2025 18:06:00 - INFO - __main__ -   epoch 1 step 1600 loss 0.069\n",
            "03/18/2025 18:06:45 - INFO - __main__ -   epoch 1 step 1700 loss 0.08226\n",
            "03/18/2025 18:07:29 - INFO - __main__ -   epoch 1 step 1800 loss 0.05862\n",
            "03/18/2025 18:08:13 - INFO - __main__ -   epoch 1 step 1900 loss 0.09765\n",
            "03/18/2025 18:08:57 - INFO - __main__ -   epoch 1 step 2000 loss 0.06733\n",
            "03/18/2025 18:09:41 - INFO - __main__ -   epoch 1 step 2100 loss 0.08317\n",
            "03/18/2025 18:10:25 - INFO - __main__ -   epoch 1 step 2200 loss 0.06455\n",
            "03/18/2025 18:11:10 - INFO - __main__ -   epoch 1 step 2300 loss 0.0836\n",
            "03/18/2025 18:11:54 - INFO - __main__ -   epoch 1 step 2400 loss 0.08372\n",
            "03/18/2025 18:12:38 - INFO - __main__ -   epoch 1 step 2500 loss 0.0729\n",
            "03/18/2025 18:13:22 - INFO - __main__ -   epoch 1 step 2600 loss 0.0922\n",
            "03/18/2025 18:14:06 - INFO - __main__ -   epoch 1 step 2700 loss 0.08466\n",
            "03/18/2025 18:14:50 - INFO - __main__ -   epoch 1 step 2800 loss 0.08178\n",
            "03/18/2025 18:15:34 - INFO - __main__ -   epoch 1 step 2900 loss 0.07907\n",
            "03/18/2025 18:16:19 - INFO - __main__ -   epoch 1 step 3000 loss 0.08069\n",
            "03/18/2025 18:17:03 - INFO - __main__ -   epoch 1 step 3100 loss 0.08318\n",
            "03/18/2025 18:17:47 - INFO - __main__ -   epoch 1 step 3200 loss 0.0866\n",
            "03/18/2025 18:18:31 - INFO - __main__ -   epoch 1 step 3300 loss 0.07283\n",
            "03/18/2025 18:19:15 - INFO - __main__ -   epoch 1 step 3400 loss 0.08228\n",
            "03/18/2025 18:19:59 - INFO - __main__ -   epoch 1 step 3500 loss 0.06859\n",
            "03/18/2025 18:20:44 - INFO - __main__ -   epoch 1 step 3600 loss 0.07864\n",
            "03/18/2025 18:21:28 - INFO - __main__ -   epoch 1 step 3700 loss 0.09211\n",
            "03/18/2025 18:22:12 - INFO - __main__ -   epoch 1 step 3800 loss 0.09907\n",
            "03/18/2025 18:22:56 - INFO - __main__ -   epoch 1 step 3900 loss 0.08544\n",
            "03/18/2025 18:23:40 - INFO - __main__ -   epoch 1 step 4000 loss 0.08779\n",
            "03/18/2025 18:24:24 - INFO - __main__ -   epoch 1 step 4100 loss 0.06552\n",
            "03/18/2025 18:25:08 - INFO - __main__ -   epoch 1 step 4200 loss 0.08552\n",
            "03/18/2025 18:25:53 - INFO - __main__ -   epoch 1 step 4300 loss 0.08763\n",
            "03/18/2025 18:26:37 - INFO - __main__ -   epoch 1 step 4400 loss 0.07321\n",
            "03/18/2025 18:27:23 - INFO - __main__ -   epoch 1 step 4500 loss 0.06758\n",
            "03/18/2025 18:28:07 - INFO - __main__ -   epoch 1 step 4600 loss 0.08768\n",
            "03/18/2025 18:28:51 - INFO - __main__ -   epoch 1 step 4700 loss 0.07398\n",
            "03/18/2025 18:29:36 - INFO - __main__ -   epoch 1 step 4800 loss 0.07816\n",
            "03/18/2025 18:30:20 - INFO - __main__ -   epoch 1 step 4900 loss 0.07908\n",
            "03/18/2025 18:31:04 - INFO - __main__ -   epoch 1 step 5000 loss 0.08662\n",
            "03/18/2025 18:31:48 - INFO - __main__ -   epoch 1 step 5100 loss 0.08559\n",
            "03/18/2025 18:32:32 - INFO - __main__ -   epoch 1 step 5200 loss 0.06899\n",
            "03/18/2025 18:33:16 - INFO - __main__ -   epoch 1 step 5300 loss 0.07768\n",
            "03/18/2025 18:34:01 - INFO - __main__ -   epoch 1 step 5400 loss 0.09284\n",
            "03/18/2025 18:34:45 - INFO - __main__ -   epoch 1 step 5500 loss 0.08006\n",
            "03/18/2025 18:35:29 - INFO - __main__ -   epoch 1 step 5600 loss 0.07915\n",
            "03/18/2025 18:36:13 - INFO - __main__ -   epoch 1 step 5700 loss 0.08663\n",
            "03/18/2025 18:36:57 - INFO - __main__ -   epoch 1 step 5800 loss 0.07985\n",
            "03/18/2025 18:37:41 - INFO - __main__ -   epoch 1 step 5900 loss 0.09002\n",
            "03/18/2025 18:38:25 - INFO - __main__ -   epoch 1 step 6000 loss 0.07571\n",
            "03/18/2025 18:39:10 - INFO - __main__ -   epoch 1 step 6100 loss 0.08217\n",
            "03/18/2025 18:39:54 - INFO - __main__ -   epoch 1 step 6200 loss 0.07921\n",
            "03/18/2025 18:40:38 - INFO - __main__ -   epoch 1 step 6300 loss 0.06981\n",
            "03/18/2025 18:41:22 - INFO - __main__ -   epoch 1 step 6400 loss 0.06926\n",
            "03/18/2025 18:42:06 - INFO - __main__ -   epoch 1 step 6500 loss 0.06988\n",
            "03/18/2025 18:42:50 - INFO - __main__ -   epoch 1 step 6600 loss 0.07353\n",
            "03/18/2025 18:43:34 - INFO - __main__ -   epoch 1 step 6700 loss 0.08902\n",
            "03/18/2025 18:44:19 - INFO - __main__ -   epoch 1 step 6800 loss 0.09795\n",
            "03/18/2025 18:45:03 - INFO - __main__ -   epoch 1 step 6900 loss 0.06432\n",
            "03/18/2025 18:45:47 - INFO - __main__ -   epoch 1 step 7000 loss 0.06048\n",
            "03/18/2025 18:46:31 - INFO - __main__ -   epoch 1 step 7100 loss 0.06519\n",
            "03/18/2025 18:47:15 - INFO - __main__ -   epoch 1 step 7200 loss 0.08094\n",
            "03/18/2025 18:47:59 - INFO - __main__ -   epoch 1 step 7300 loss 0.07041\n",
            "03/18/2025 18:48:44 - INFO - __main__ -   epoch 1 step 7400 loss 0.07531\n",
            "03/18/2025 18:49:28 - INFO - __main__ -   epoch 1 step 7500 loss 0.08827\n",
            "03/18/2025 18:50:12 - INFO - __main__ -   epoch 1 step 7600 loss 0.06642\n",
            "03/18/2025 18:50:56 - INFO - __main__ -   epoch 1 step 7700 loss 0.08527\n",
            "03/18/2025 18:51:40 - INFO - __main__ -   epoch 1 step 7800 loss 0.06858\n",
            "03/18/2025 18:52:56 - INFO - __main__ -   ***** Running evaluation *****\n",
            "03/18/2025 18:52:56 - INFO - __main__ -     Num queries = 13914\n",
            "03/18/2025 18:52:56 - INFO - __main__ -     Num codes = 43827\n",
            "03/18/2025 18:52:56 - INFO - __main__ -     Batch size = 64\n",
            "03/18/2025 18:55:32 - INFO - __main__ -     Success@1 = 0.0\n",
            "03/18/2025 18:55:32 - INFO - __main__ -     Success@5 = 0.0001\n",
            "03/18/2025 18:55:32 - INFO - __main__ -     Success@10 = 0.0004\n",
            "03/18/2025 18:55:32 - INFO - __main__ -     MRR = 0.6073\n",
            "03/18/2025 18:55:32 - INFO - __main__ -     ********************\n",
            "03/18/2025 18:55:32 - INFO - __main__ -     Best mrr:0.6073\n",
            "03/18/2025 18:55:32 - INFO - __main__ -     ********************\n",
            "03/18/2025 18:55:34 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/CoSHC/CodeBERT/models/python/checkpoint-best-mrr/model.bin\n",
            "03/18/2025 18:56:18 - INFO - __main__ -   epoch 2 step 100 loss 0.05348\n",
            "03/18/2025 18:57:03 - INFO - __main__ -   epoch 2 step 200 loss 0.05691\n",
            "03/18/2025 18:57:47 - INFO - __main__ -   epoch 2 step 300 loss 0.06443\n",
            "03/18/2025 18:58:31 - INFO - __main__ -   epoch 2 step 400 loss 0.04856\n",
            "03/18/2025 18:59:15 - INFO - __main__ -   epoch 2 step 500 loss 0.06878\n",
            "03/18/2025 18:59:59 - INFO - __main__ -   epoch 2 step 600 loss 0.04873\n",
            "03/18/2025 19:00:43 - INFO - __main__ -   epoch 2 step 700 loss 0.05891\n",
            "03/18/2025 19:01:27 - INFO - __main__ -   epoch 2 step 800 loss 0.05524\n",
            "03/18/2025 19:02:12 - INFO - __main__ -   epoch 2 step 900 loss 0.05278\n",
            "03/18/2025 19:02:56 - INFO - __main__ -   epoch 2 step 1000 loss 0.0646\n",
            "03/18/2025 19:03:40 - INFO - __main__ -   epoch 2 step 1100 loss 0.06552\n",
            "03/18/2025 19:04:24 - INFO - __main__ -   epoch 2 step 1200 loss 0.06173\n",
            "03/18/2025 19:05:08 - INFO - __main__ -   epoch 2 step 1300 loss 0.05322\n",
            "03/18/2025 19:05:53 - INFO - __main__ -   epoch 2 step 1400 loss 0.07049\n",
            "03/18/2025 19:06:37 - INFO - __main__ -   epoch 2 step 1500 loss 0.05931\n",
            "03/18/2025 19:07:21 - INFO - __main__ -   epoch 2 step 1600 loss 0.05044\n",
            "03/18/2025 19:08:05 - INFO - __main__ -   epoch 2 step 1700 loss 0.05628\n",
            "03/18/2025 19:08:49 - INFO - __main__ -   epoch 2 step 1800 loss 0.04427\n",
            "03/18/2025 19:09:34 - INFO - __main__ -   epoch 2 step 1900 loss 0.04674\n",
            "03/18/2025 19:10:18 - INFO - __main__ -   epoch 2 step 2000 loss 0.05009\n",
            "03/18/2025 19:11:02 - INFO - __main__ -   epoch 2 step 2100 loss 0.04666\n",
            "03/18/2025 19:11:46 - INFO - __main__ -   epoch 2 step 2200 loss 0.0546\n",
            "03/18/2025 19:12:30 - INFO - __main__ -   epoch 2 step 2300 loss 0.06852\n",
            "03/18/2025 19:13:14 - INFO - __main__ -   epoch 2 step 2400 loss 0.05527\n",
            "03/18/2025 19:13:59 - INFO - __main__ -   epoch 2 step 2500 loss 0.07383\n",
            "03/18/2025 19:14:43 - INFO - __main__ -   epoch 2 step 2600 loss 0.05023\n",
            "03/18/2025 19:15:27 - INFO - __main__ -   epoch 2 step 2700 loss 0.04709\n",
            "03/18/2025 19:16:11 - INFO - __main__ -   epoch 2 step 2800 loss 0.05026\n",
            "03/18/2025 19:16:56 - INFO - __main__ -   epoch 2 step 2900 loss 0.05776\n",
            "03/18/2025 19:17:40 - INFO - __main__ -   epoch 2 step 3000 loss 0.04582\n",
            "03/18/2025 19:18:24 - INFO - __main__ -   epoch 2 step 3100 loss 0.05735\n",
            "03/18/2025 19:19:08 - INFO - __main__ -   epoch 2 step 3200 loss 0.04824\n",
            "03/18/2025 19:19:52 - INFO - __main__ -   epoch 2 step 3300 loss 0.06092\n",
            "03/18/2025 19:20:36 - INFO - __main__ -   epoch 2 step 3400 loss 0.05412\n",
            "03/18/2025 19:21:21 - INFO - __main__ -   epoch 2 step 3500 loss 0.05644\n",
            "03/18/2025 19:22:05 - INFO - __main__ -   epoch 2 step 3600 loss 0.06139\n",
            "03/18/2025 19:22:49 - INFO - __main__ -   epoch 2 step 3700 loss 0.05029\n",
            "03/18/2025 19:23:33 - INFO - __main__ -   epoch 2 step 3800 loss 0.04187\n",
            "03/18/2025 19:24:17 - INFO - __main__ -   epoch 2 step 3900 loss 0.07532\n",
            "03/18/2025 19:25:01 - INFO - __main__ -   epoch 2 step 4000 loss 0.06117\n",
            "03/18/2025 19:25:46 - INFO - __main__ -   epoch 2 step 4100 loss 0.05638\n",
            "03/18/2025 19:26:30 - INFO - __main__ -   epoch 2 step 4200 loss 0.05617\n",
            "03/18/2025 19:27:14 - INFO - __main__ -   epoch 2 step 4300 loss 0.06141\n",
            "03/18/2025 19:27:58 - INFO - __main__ -   epoch 2 step 4400 loss 0.05539\n",
            "03/18/2025 19:28:42 - INFO - __main__ -   epoch 2 step 4500 loss 0.06203\n",
            "03/18/2025 19:29:27 - INFO - __main__ -   epoch 2 step 4600 loss 0.04658\n",
            "03/18/2025 19:30:11 - INFO - __main__ -   epoch 2 step 4700 loss 0.05277\n",
            "03/18/2025 19:30:55 - INFO - __main__ -   epoch 2 step 4800 loss 0.06272\n",
            "03/18/2025 19:31:39 - INFO - __main__ -   epoch 2 step 4900 loss 0.05628\n",
            "03/18/2025 19:32:23 - INFO - __main__ -   epoch 2 step 5000 loss 0.06892\n",
            "03/18/2025 19:33:08 - INFO - __main__ -   epoch 2 step 5100 loss 0.05759\n",
            "03/18/2025 19:33:52 - INFO - __main__ -   epoch 2 step 5200 loss 0.04403\n",
            "03/18/2025 19:34:36 - INFO - __main__ -   epoch 2 step 5300 loss 0.05273\n",
            "03/18/2025 19:35:20 - INFO - __main__ -   epoch 2 step 5400 loss 0.07768\n",
            "03/18/2025 19:36:06 - INFO - __main__ -   epoch 2 step 5500 loss 0.04399\n",
            "03/18/2025 19:36:51 - INFO - __main__ -   epoch 2 step 5600 loss 0.05199\n",
            "03/18/2025 19:37:35 - INFO - __main__ -   epoch 2 step 5700 loss 0.05868\n",
            "03/18/2025 19:38:19 - INFO - __main__ -   epoch 2 step 5800 loss 0.05221\n",
            "03/18/2025 19:39:03 - INFO - __main__ -   epoch 2 step 5900 loss 0.04825\n",
            "03/18/2025 19:39:47 - INFO - __main__ -   epoch 2 step 6000 loss 0.05476\n",
            "03/18/2025 19:40:31 - INFO - __main__ -   epoch 2 step 6100 loss 0.05039\n",
            "03/18/2025 19:41:16 - INFO - __main__ -   epoch 2 step 6200 loss 0.0525\n",
            "03/18/2025 19:42:00 - INFO - __main__ -   epoch 2 step 6300 loss 0.06245\n",
            "03/18/2025 19:42:44 - INFO - __main__ -   epoch 2 step 6400 loss 0.07383\n",
            "03/18/2025 19:43:28 - INFO - __main__ -   epoch 2 step 6500 loss 0.04366\n",
            "03/18/2025 19:44:12 - INFO - __main__ -   epoch 2 step 6600 loss 0.05348\n",
            "03/18/2025 19:44:57 - INFO - __main__ -   epoch 2 step 6700 loss 0.04457\n",
            "03/18/2025 19:45:41 - INFO - __main__ -   epoch 2 step 6800 loss 0.05583\n",
            "03/18/2025 19:46:25 - INFO - __main__ -   epoch 2 step 6900 loss 0.05679\n",
            "03/18/2025 19:47:09 - INFO - __main__ -   epoch 2 step 7000 loss 0.0423\n",
            "03/18/2025 19:47:53 - INFO - __main__ -   epoch 2 step 7100 loss 0.06645\n",
            "03/18/2025 19:48:37 - INFO - __main__ -   epoch 2 step 7200 loss 0.0681\n",
            "03/18/2025 19:49:22 - INFO - __main__ -   epoch 2 step 7300 loss 0.05268\n",
            "03/18/2025 19:50:06 - INFO - __main__ -   epoch 2 step 7400 loss 0.05917\n",
            "03/18/2025 19:50:50 - INFO - __main__ -   epoch 2 step 7500 loss 0.05906\n",
            "03/18/2025 19:51:34 - INFO - __main__ -   epoch 2 step 7600 loss 0.034\n",
            "03/18/2025 19:52:18 - INFO - __main__ -   epoch 2 step 7700 loss 0.06696\n",
            "03/18/2025 19:53:02 - INFO - __main__ -   epoch 2 step 7800 loss 0.05824\n",
            "03/18/2025 19:54:18 - INFO - __main__ -   ***** Running evaluation *****\n",
            "03/18/2025 19:54:18 - INFO - __main__ -     Num queries = 13914\n",
            "03/18/2025 19:54:18 - INFO - __main__ -     Num codes = 43827\n",
            "03/18/2025 19:54:18 - INFO - __main__ -     Batch size = 64\n",
            "03/18/2025 19:56:54 - INFO - __main__ -     Success@1 = 0.0\n",
            "03/18/2025 19:56:54 - INFO - __main__ -     Success@5 = 0.0001\n",
            "03/18/2025 19:56:54 - INFO - __main__ -     Success@10 = 0.0004\n",
            "03/18/2025 19:56:54 - INFO - __main__ -     MRR = 0.6205\n",
            "03/18/2025 19:56:54 - INFO - __main__ -     ********************\n",
            "03/18/2025 19:56:54 - INFO - __main__ -     Best mrr:0.6205\n",
            "03/18/2025 19:56:54 - INFO - __main__ -     ********************\n",
            "03/18/2025 19:56:56 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/CoSHC/CodeBERT/models/python/checkpoint-best-mrr/model.bin\n",
            "03/18/2025 19:57:41 - INFO - __main__ -   epoch 3 step 100 loss 0.04156\n",
            "03/18/2025 19:58:25 - INFO - __main__ -   epoch 3 step 200 loss 0.03488\n",
            "03/18/2025 19:59:09 - INFO - __main__ -   epoch 3 step 300 loss 0.03725\n",
            "03/18/2025 19:59:53 - INFO - __main__ -   epoch 3 step 400 loss 0.03866\n",
            "03/18/2025 20:00:37 - INFO - __main__ -   epoch 3 step 500 loss 0.0388\n",
            "03/18/2025 20:01:22 - INFO - __main__ -   epoch 3 step 600 loss 0.05628\n",
            "03/18/2025 20:02:06 - INFO - __main__ -   epoch 3 step 700 loss 0.04252\n",
            "03/18/2025 20:02:50 - INFO - __main__ -   epoch 3 step 800 loss 0.03846\n",
            "03/18/2025 20:03:34 - INFO - __main__ -   epoch 3 step 900 loss 0.03841\n",
            "03/18/2025 20:04:18 - INFO - __main__ -   epoch 3 step 1000 loss 0.04029\n",
            "03/18/2025 20:05:02 - INFO - __main__ -   epoch 3 step 1100 loss 0.05129\n",
            "03/18/2025 20:05:47 - INFO - __main__ -   epoch 3 step 1200 loss 0.04343\n",
            "03/18/2025 20:06:31 - INFO - __main__ -   epoch 3 step 1300 loss 0.05241\n",
            "03/18/2025 20:07:15 - INFO - __main__ -   epoch 3 step 1400 loss 0.05036\n",
            "03/18/2025 20:07:59 - INFO - __main__ -   epoch 3 step 1500 loss 0.04184\n",
            "03/18/2025 20:08:43 - INFO - __main__ -   epoch 3 step 1600 loss 0.03881\n",
            "03/18/2025 20:09:27 - INFO - __main__ -   epoch 3 step 1700 loss 0.03693\n",
            "03/18/2025 20:10:12 - INFO - __main__ -   epoch 3 step 1800 loss 0.03977\n",
            "03/18/2025 20:10:56 - INFO - __main__ -   epoch 3 step 1900 loss 0.03575\n",
            "03/18/2025 20:11:40 - INFO - __main__ -   epoch 3 step 2000 loss 0.05798\n",
            "03/18/2025 20:12:24 - INFO - __main__ -   epoch 3 step 2100 loss 0.04096\n",
            "03/18/2025 20:13:08 - INFO - __main__ -   epoch 3 step 2200 loss 0.03884\n",
            "03/18/2025 20:13:52 - INFO - __main__ -   epoch 3 step 2300 loss 0.05014\n",
            "03/18/2025 20:14:37 - INFO - __main__ -   epoch 3 step 2400 loss 0.04884\n",
            "03/18/2025 20:15:21 - INFO - __main__ -   epoch 3 step 2500 loss 0.05711\n",
            "03/18/2025 20:16:05 - INFO - __main__ -   epoch 3 step 2600 loss 0.05519\n",
            "03/18/2025 20:16:49 - INFO - __main__ -   epoch 3 step 2700 loss 0.04689\n",
            "03/18/2025 20:17:33 - INFO - __main__ -   epoch 3 step 2800 loss 0.03882\n",
            "03/18/2025 20:18:18 - INFO - __main__ -   epoch 3 step 2900 loss 0.04027\n",
            "03/18/2025 20:19:02 - INFO - __main__ -   epoch 3 step 3000 loss 0.04672\n",
            "03/18/2025 20:19:46 - INFO - __main__ -   epoch 3 step 3100 loss 0.04352\n",
            "03/18/2025 20:20:30 - INFO - __main__ -   epoch 3 step 3200 loss 0.05825\n",
            "03/18/2025 20:21:14 - INFO - __main__ -   epoch 3 step 3300 loss 0.02701\n",
            "03/18/2025 20:21:59 - INFO - __main__ -   epoch 3 step 3400 loss 0.05452\n",
            "03/18/2025 20:22:43 - INFO - __main__ -   epoch 3 step 3500 loss 0.03627\n",
            "03/18/2025 20:23:27 - INFO - __main__ -   epoch 3 step 3600 loss 0.04579\n",
            "03/18/2025 20:24:11 - INFO - __main__ -   epoch 3 step 3700 loss 0.03745\n",
            "03/18/2025 20:24:55 - INFO - __main__ -   epoch 3 step 3800 loss 0.05114\n",
            "03/18/2025 20:25:39 - INFO - __main__ -   epoch 3 step 3900 loss 0.05536\n",
            "03/18/2025 20:26:24 - INFO - __main__ -   epoch 3 step 4000 loss 0.05443\n",
            "03/18/2025 20:27:08 - INFO - __main__ -   epoch 3 step 4100 loss 0.04595\n",
            "03/18/2025 20:27:52 - INFO - __main__ -   epoch 3 step 4200 loss 0.04577\n",
            "03/18/2025 20:28:36 - INFO - __main__ -   epoch 3 step 4300 loss 0.05423\n",
            "03/18/2025 20:29:20 - INFO - __main__ -   epoch 3 step 4400 loss 0.05252\n",
            "03/18/2025 20:30:04 - INFO - __main__ -   epoch 3 step 4500 loss 0.03999\n",
            "03/18/2025 20:30:49 - INFO - __main__ -   epoch 3 step 4600 loss 0.03591\n",
            "03/18/2025 20:31:33 - INFO - __main__ -   epoch 3 step 4700 loss 0.02736\n",
            "03/18/2025 20:32:17 - INFO - __main__ -   epoch 3 step 4800 loss 0.02448\n",
            "03/18/2025 20:33:01 - INFO - __main__ -   epoch 3 step 4900 loss 0.05952\n",
            "03/18/2025 20:33:45 - INFO - __main__ -   epoch 3 step 5000 loss 0.05386\n",
            "03/18/2025 20:34:29 - INFO - __main__ -   epoch 3 step 5100 loss 0.05319\n",
            "03/18/2025 20:35:14 - INFO - __main__ -   epoch 3 step 5200 loss 0.04186\n",
            "03/18/2025 20:35:58 - INFO - __main__ -   epoch 3 step 5300 loss 0.04841\n",
            "03/18/2025 20:36:42 - INFO - __main__ -   epoch 3 step 5400 loss 0.04419\n",
            "03/18/2025 20:37:26 - INFO - __main__ -   epoch 3 step 5500 loss 0.04795\n",
            "03/18/2025 20:38:10 - INFO - __main__ -   epoch 3 step 5600 loss 0.03505\n",
            "03/18/2025 20:38:54 - INFO - __main__ -   epoch 3 step 5700 loss 0.03124\n",
            "03/18/2025 20:39:39 - INFO - __main__ -   epoch 3 step 5800 loss 0.03572\n",
            "03/18/2025 20:40:23 - INFO - __main__ -   epoch 3 step 5900 loss 0.05516\n",
            "03/18/2025 20:41:07 - INFO - __main__ -   epoch 3 step 6000 loss 0.04275\n",
            "03/18/2025 20:41:51 - INFO - __main__ -   epoch 3 step 6100 loss 0.04808\n",
            "03/18/2025 20:42:35 - INFO - __main__ -   epoch 3 step 6200 loss 0.03609\n",
            "03/18/2025 20:43:20 - INFO - __main__ -   epoch 3 step 6300 loss 0.04431\n",
            "03/18/2025 20:44:04 - INFO - __main__ -   epoch 3 step 6400 loss 0.0543\n",
            "03/18/2025 20:44:48 - INFO - __main__ -   epoch 3 step 6500 loss 0.03981\n",
            "03/18/2025 20:45:34 - INFO - __main__ -   epoch 3 step 6600 loss 0.03098\n",
            "03/18/2025 20:46:18 - INFO - __main__ -   epoch 3 step 6700 loss 0.03006\n",
            "03/18/2025 20:47:03 - INFO - __main__ -   epoch 3 step 6800 loss 0.04392\n",
            "03/18/2025 20:47:47 - INFO - __main__ -   epoch 3 step 6900 loss 0.04173\n",
            "03/18/2025 20:48:31 - INFO - __main__ -   epoch 3 step 7000 loss 0.04057\n",
            "03/18/2025 20:49:15 - INFO - __main__ -   epoch 3 step 7100 loss 0.04072\n",
            "03/18/2025 20:49:59 - INFO - __main__ -   epoch 3 step 7200 loss 0.04227\n",
            "03/18/2025 20:50:43 - INFO - __main__ -   epoch 3 step 7300 loss 0.03317\n",
            "03/18/2025 20:51:28 - INFO - __main__ -   epoch 3 step 7400 loss 0.03296\n",
            "03/18/2025 20:52:12 - INFO - __main__ -   epoch 3 step 7500 loss 0.03893\n",
            "03/18/2025 20:52:56 - INFO - __main__ -   epoch 3 step 7600 loss 0.05516\n",
            "03/18/2025 20:53:40 - INFO - __main__ -   epoch 3 step 7700 loss 0.06864\n",
            "03/18/2025 20:54:24 - INFO - __main__ -   epoch 3 step 7800 loss 0.04257\n",
            "03/18/2025 20:55:41 - INFO - __main__ -   ***** Running evaluation *****\n",
            "03/18/2025 20:55:41 - INFO - __main__ -     Num queries = 13914\n",
            "03/18/2025 20:55:41 - INFO - __main__ -     Num codes = 43827\n",
            "03/18/2025 20:55:41 - INFO - __main__ -     Batch size = 64\n",
            "03/18/2025 20:58:16 - INFO - __main__ -     Success@1 = 0.0\n",
            "03/18/2025 20:58:16 - INFO - __main__ -     Success@5 = 0.0001\n",
            "03/18/2025 20:58:16 - INFO - __main__ -     Success@10 = 0.0004\n",
            "03/18/2025 20:58:16 - INFO - __main__ -     MRR = 0.6283\n",
            "03/18/2025 20:58:16 - INFO - __main__ -     ********************\n",
            "03/18/2025 20:58:16 - INFO - __main__ -     Best mrr:0.6283\n",
            "03/18/2025 20:58:16 - INFO - __main__ -     ********************\n",
            "03/18/2025 20:58:19 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/CoSHC/CodeBERT/models/python/checkpoint-best-mrr/model.bin\n",
            "03/18/2025 20:59:03 - INFO - __main__ -   epoch 4 step 100 loss 0.03222\n",
            "03/18/2025 20:59:47 - INFO - __main__ -   epoch 4 step 200 loss 0.03545\n",
            "03/18/2025 21:00:31 - INFO - __main__ -   epoch 4 step 300 loss 0.02437\n",
            "03/18/2025 21:01:16 - INFO - __main__ -   epoch 4 step 400 loss 0.0342\n",
            "03/18/2025 21:02:00 - INFO - __main__ -   epoch 4 step 500 loss 0.03296\n",
            "03/18/2025 21:02:44 - INFO - __main__ -   epoch 4 step 600 loss 0.03411\n",
            "03/18/2025 21:03:28 - INFO - __main__ -   epoch 4 step 700 loss 0.02633\n",
            "03/18/2025 21:04:12 - INFO - __main__ -   epoch 4 step 800 loss 0.04243\n",
            "03/18/2025 21:04:57 - INFO - __main__ -   epoch 4 step 900 loss 0.02909\n",
            "03/18/2025 21:05:41 - INFO - __main__ -   epoch 4 step 1000 loss 0.03417\n",
            "03/18/2025 21:06:25 - INFO - __main__ -   epoch 4 step 1100 loss 0.02939\n",
            "03/18/2025 21:07:09 - INFO - __main__ -   epoch 4 step 1200 loss 0.03874\n",
            "03/18/2025 21:07:53 - INFO - __main__ -   epoch 4 step 1300 loss 0.0261\n",
            "03/18/2025 21:08:38 - INFO - __main__ -   epoch 4 step 1400 loss 0.02728\n",
            "03/18/2025 21:09:22 - INFO - __main__ -   epoch 4 step 1500 loss 0.02963\n",
            "03/18/2025 21:10:06 - INFO - __main__ -   epoch 4 step 1600 loss 0.02733\n",
            "03/18/2025 21:10:51 - INFO - __main__ -   epoch 4 step 1700 loss 0.02894\n",
            "03/18/2025 21:11:35 - INFO - __main__ -   epoch 4 step 1800 loss 0.03041\n",
            "03/18/2025 21:12:19 - INFO - __main__ -   epoch 4 step 1900 loss 0.03814\n",
            "03/18/2025 21:13:03 - INFO - __main__ -   epoch 4 step 2000 loss 0.03376\n",
            "03/18/2025 21:13:47 - INFO - __main__ -   epoch 4 step 2100 loss 0.02747\n",
            "03/18/2025 21:14:31 - INFO - __main__ -   epoch 4 step 2200 loss 0.0226\n",
            "03/18/2025 21:15:16 - INFO - __main__ -   epoch 4 step 2300 loss 0.0357\n",
            "03/18/2025 21:16:00 - INFO - __main__ -   epoch 4 step 2400 loss 0.02994\n",
            "03/18/2025 21:16:44 - INFO - __main__ -   epoch 4 step 2500 loss 0.03133\n",
            "03/18/2025 21:17:28 - INFO - __main__ -   epoch 4 step 2600 loss 0.04905\n",
            "03/18/2025 21:18:12 - INFO - __main__ -   epoch 4 step 2700 loss 0.0401\n",
            "03/18/2025 21:18:57 - INFO - __main__ -   epoch 4 step 2800 loss 0.01954\n",
            "03/18/2025 21:19:41 - INFO - __main__ -   epoch 4 step 2900 loss 0.02779\n",
            "03/18/2025 21:20:25 - INFO - __main__ -   epoch 4 step 3000 loss 0.03645\n",
            "03/18/2025 21:21:09 - INFO - __main__ -   epoch 4 step 3100 loss 0.03771\n",
            "03/18/2025 21:21:53 - INFO - __main__ -   epoch 4 step 3200 loss 0.02687\n",
            "03/18/2025 21:22:37 - INFO - __main__ -   epoch 4 step 3300 loss 0.03973\n",
            "03/18/2025 21:23:22 - INFO - __main__ -   epoch 4 step 3400 loss 0.02654\n",
            "03/18/2025 21:24:06 - INFO - __main__ -   epoch 4 step 3500 loss 0.03063\n",
            "03/18/2025 21:24:50 - INFO - __main__ -   epoch 4 step 3600 loss 0.04388\n",
            "03/18/2025 21:25:34 - INFO - __main__ -   epoch 4 step 3700 loss 0.02392\n",
            "03/18/2025 21:26:18 - INFO - __main__ -   epoch 4 step 3800 loss 0.02957\n",
            "03/18/2025 21:27:02 - INFO - __main__ -   epoch 4 step 3900 loss 0.03989\n",
            "03/18/2025 21:27:47 - INFO - __main__ -   epoch 4 step 4000 loss 0.02729\n",
            "03/18/2025 21:28:31 - INFO - __main__ -   epoch 4 step 4100 loss 0.05083\n",
            "03/18/2025 21:29:15 - INFO - __main__ -   epoch 4 step 4200 loss 0.03759\n",
            "03/18/2025 21:29:59 - INFO - __main__ -   epoch 4 step 4300 loss 0.06043\n",
            "03/18/2025 21:30:43 - INFO - __main__ -   epoch 4 step 4400 loss 0.0212\n",
            "03/18/2025 21:31:27 - INFO - __main__ -   epoch 4 step 4500 loss 0.03692\n",
            "03/18/2025 21:32:12 - INFO - __main__ -   epoch 4 step 4600 loss 0.03403\n",
            "03/18/2025 21:32:56 - INFO - __main__ -   epoch 4 step 4700 loss 0.02009\n",
            "03/18/2025 21:33:40 - INFO - __main__ -   epoch 4 step 4800 loss 0.01646\n",
            "03/18/2025 21:34:24 - INFO - __main__ -   epoch 4 step 4900 loss 0.04673\n",
            "03/18/2025 21:35:08 - INFO - __main__ -   epoch 4 step 5000 loss 0.04157\n",
            "03/18/2025 21:35:53 - INFO - __main__ -   epoch 4 step 5100 loss 0.04341\n",
            "03/18/2025 21:36:37 - INFO - __main__ -   epoch 4 step 5200 loss 0.02974\n",
            "03/18/2025 21:37:21 - INFO - __main__ -   epoch 4 step 5300 loss 0.02764\n",
            "03/18/2025 21:38:05 - INFO - __main__ -   epoch 4 step 5400 loss 0.03108\n",
            "03/18/2025 21:38:49 - INFO - __main__ -   epoch 4 step 5500 loss 0.02127\n",
            "03/18/2025 21:39:33 - INFO - __main__ -   epoch 4 step 5600 loss 0.02641\n",
            "03/18/2025 21:40:18 - INFO - __main__ -   epoch 4 step 5700 loss 0.0417\n",
            "03/18/2025 21:41:02 - INFO - __main__ -   epoch 4 step 5800 loss 0.03146\n",
            "03/18/2025 21:41:46 - INFO - __main__ -   epoch 4 step 5900 loss 0.02964\n",
            "03/18/2025 21:42:30 - INFO - __main__ -   epoch 4 step 6000 loss 0.03502\n",
            "03/18/2025 21:43:14 - INFO - __main__ -   epoch 4 step 6100 loss 0.03451\n",
            "03/18/2025 21:43:59 - INFO - __main__ -   epoch 4 step 6200 loss 0.03163\n",
            "03/18/2025 21:44:43 - INFO - __main__ -   epoch 4 step 6300 loss 0.02642\n",
            "03/18/2025 21:45:27 - INFO - __main__ -   epoch 4 step 6400 loss 0.03594\n",
            "03/18/2025 21:46:11 - INFO - __main__ -   epoch 4 step 6500 loss 0.03249\n",
            "03/18/2025 21:46:55 - INFO - __main__ -   epoch 4 step 6600 loss 0.02535\n",
            "03/18/2025 21:47:40 - INFO - __main__ -   epoch 4 step 6700 loss 0.02246\n",
            "03/18/2025 21:48:24 - INFO - __main__ -   epoch 4 step 6800 loss 0.03848\n",
            "03/18/2025 21:49:08 - INFO - __main__ -   epoch 4 step 6900 loss 0.04094\n",
            "03/18/2025 21:49:52 - INFO - __main__ -   epoch 4 step 7000 loss 0.03853\n",
            "03/18/2025 21:50:37 - INFO - __main__ -   epoch 4 step 7100 loss 0.02922\n",
            "03/18/2025 21:51:21 - INFO - __main__ -   epoch 4 step 7200 loss 0.04197\n",
            "03/18/2025 21:52:05 - INFO - __main__ -   epoch 4 step 7300 loss 0.02979\n",
            "03/18/2025 21:52:50 - INFO - __main__ -   epoch 4 step 7400 loss 0.02391\n",
            "03/18/2025 21:53:34 - INFO - __main__ -   epoch 4 step 7500 loss 0.04382\n",
            "03/18/2025 21:54:18 - INFO - __main__ -   epoch 4 step 7600 loss 0.03739\n",
            "03/18/2025 21:55:02 - INFO - __main__ -   epoch 4 step 7700 loss 0.03449\n",
            "03/18/2025 21:55:47 - INFO - __main__ -   epoch 4 step 7800 loss 0.02894\n",
            "03/18/2025 21:57:03 - INFO - __main__ -   ***** Running evaluation *****\n",
            "03/18/2025 21:57:03 - INFO - __main__ -     Num queries = 13914\n",
            "03/18/2025 21:57:03 - INFO - __main__ -     Num codes = 43827\n",
            "03/18/2025 21:57:03 - INFO - __main__ -     Batch size = 64\n",
            "03/18/2025 21:59:39 - INFO - __main__ -     Success@1 = 0.0\n",
            "03/18/2025 21:59:39 - INFO - __main__ -     Success@5 = 0.0001\n",
            "03/18/2025 21:59:39 - INFO - __main__ -     Success@10 = 0.0004\n",
            "03/18/2025 21:59:39 - INFO - __main__ -     MRR = 0.6319\n",
            "03/18/2025 21:59:39 - INFO - __main__ -     ********************\n",
            "03/18/2025 21:59:39 - INFO - __main__ -     Best mrr:0.6319\n",
            "03/18/2025 21:59:39 - INFO - __main__ -     ********************\n",
            "03/18/2025 21:59:41 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/CoSHC/CodeBERT/models/python/checkpoint-best-mrr/model.bin\n",
            "03/18/2025 22:00:26 - INFO - __main__ -   epoch 5 step 100 loss 0.03064\n",
            "03/18/2025 22:01:10 - INFO - __main__ -   epoch 5 step 200 loss 0.03759\n",
            "03/18/2025 22:01:54 - INFO - __main__ -   epoch 5 step 300 loss 0.0228\n",
            "03/18/2025 22:02:38 - INFO - __main__ -   epoch 5 step 400 loss 0.02687\n",
            "03/18/2025 22:03:23 - INFO - __main__ -   epoch 5 step 500 loss 0.02742\n",
            "03/18/2025 22:04:07 - INFO - __main__ -   epoch 5 step 600 loss 0.02702\n",
            "03/18/2025 22:04:51 - INFO - __main__ -   epoch 5 step 700 loss 0.02145\n",
            "03/18/2025 22:05:35 - INFO - __main__ -   epoch 5 step 800 loss 0.01421\n",
            "03/18/2025 22:06:22 - INFO - __main__ -   epoch 5 step 900 loss 0.02149\n",
            "03/18/2025 22:07:06 - INFO - __main__ -   epoch 5 step 1000 loss 0.02827\n",
            "03/18/2025 22:07:50 - INFO - __main__ -   epoch 5 step 1100 loss 0.02746\n",
            "03/18/2025 22:08:35 - INFO - __main__ -   epoch 5 step 1200 loss 0.032\n",
            "03/18/2025 22:09:19 - INFO - __main__ -   epoch 5 step 1300 loss 0.03658\n",
            "03/18/2025 22:10:03 - INFO - __main__ -   epoch 5 step 1400 loss 0.02166\n",
            "03/18/2025 22:10:47 - INFO - __main__ -   epoch 5 step 1500 loss 0.03416\n",
            "03/18/2025 22:11:32 - INFO - __main__ -   epoch 5 step 1600 loss 0.02528\n",
            "03/18/2025 22:12:16 - INFO - __main__ -   epoch 5 step 1700 loss 0.03495\n",
            "03/18/2025 22:13:00 - INFO - __main__ -   epoch 5 step 1800 loss 0.02521\n",
            "03/18/2025 22:13:45 - INFO - __main__ -   epoch 5 step 1900 loss 0.02166\n",
            "03/18/2025 22:14:29 - INFO - __main__ -   epoch 5 step 2000 loss 0.02946\n",
            "03/18/2025 22:15:13 - INFO - __main__ -   epoch 5 step 2100 loss 0.02434\n",
            "03/18/2025 22:15:57 - INFO - __main__ -   epoch 5 step 2200 loss 0.0261\n",
            "03/18/2025 22:16:42 - INFO - __main__ -   epoch 5 step 2300 loss 0.02648\n",
            "03/18/2025 22:17:26 - INFO - __main__ -   epoch 5 step 2400 loss 0.02505\n",
            "03/18/2025 22:18:10 - INFO - __main__ -   epoch 5 step 2500 loss 0.03283\n",
            "03/18/2025 22:18:54 - INFO - __main__ -   epoch 5 step 2600 loss 0.02691\n",
            "03/18/2025 22:19:39 - INFO - __main__ -   epoch 5 step 2700 loss 0.02455\n",
            "03/18/2025 22:20:23 - INFO - __main__ -   epoch 5 step 2800 loss 0.02973\n",
            "03/18/2025 22:21:07 - INFO - __main__ -   epoch 5 step 2900 loss 0.03177\n",
            "03/18/2025 22:21:51 - INFO - __main__ -   epoch 5 step 3000 loss 0.03423\n",
            "03/18/2025 22:22:36 - INFO - __main__ -   epoch 5 step 3100 loss 0.02442\n",
            "03/18/2025 22:23:20 - INFO - __main__ -   epoch 5 step 3200 loss 0.03067\n",
            "03/18/2025 22:24:04 - INFO - __main__ -   epoch 5 step 3300 loss 0.03331\n",
            "03/18/2025 22:24:48 - INFO - __main__ -   epoch 5 step 3400 loss 0.02136\n",
            "03/18/2025 22:25:33 - INFO - __main__ -   epoch 5 step 3500 loss 0.03103\n",
            "03/18/2025 22:26:17 - INFO - __main__ -   epoch 5 step 3600 loss 0.04001\n",
            "03/18/2025 22:27:01 - INFO - __main__ -   epoch 5 step 3700 loss 0.03557\n",
            "03/18/2025 22:27:45 - INFO - __main__ -   epoch 5 step 3800 loss 0.04114\n",
            "03/18/2025 22:28:30 - INFO - __main__ -   epoch 5 step 3900 loss 0.02089\n",
            "03/18/2025 22:29:14 - INFO - __main__ -   epoch 5 step 4000 loss 0.04275\n",
            "03/18/2025 22:29:58 - INFO - __main__ -   epoch 5 step 4100 loss 0.02286\n",
            "03/18/2025 22:30:42 - INFO - __main__ -   epoch 5 step 4200 loss 0.03497\n",
            "03/18/2025 22:31:27 - INFO - __main__ -   epoch 5 step 4300 loss 0.03175\n",
            "03/18/2025 22:32:11 - INFO - __main__ -   epoch 5 step 4400 loss 0.0368\n",
            "03/18/2025 22:32:55 - INFO - __main__ -   epoch 5 step 4500 loss 0.03882\n",
            "03/18/2025 22:33:39 - INFO - __main__ -   epoch 5 step 4600 loss 0.0201\n",
            "03/18/2025 22:34:24 - INFO - __main__ -   epoch 5 step 4700 loss 0.02103\n",
            "03/18/2025 22:35:08 - INFO - __main__ -   epoch 5 step 4800 loss 0.0396\n",
            "03/18/2025 22:35:52 - INFO - __main__ -   epoch 5 step 4900 loss 0.04001\n",
            "03/18/2025 22:36:36 - INFO - __main__ -   epoch 5 step 5000 loss 0.02703\n",
            "03/18/2025 22:37:21 - INFO - __main__ -   epoch 5 step 5100 loss 0.02359\n",
            "03/18/2025 22:38:05 - INFO - __main__ -   epoch 5 step 5200 loss 0.03377\n",
            "03/18/2025 22:38:49 - INFO - __main__ -   epoch 5 step 5300 loss 0.02255\n",
            "03/18/2025 22:39:33 - INFO - __main__ -   epoch 5 step 5400 loss 0.01859\n",
            "03/18/2025 22:40:18 - INFO - __main__ -   epoch 5 step 5500 loss 0.03606\n",
            "03/18/2025 22:41:02 - INFO - __main__ -   epoch 5 step 5600 loss 0.03383\n",
            "03/18/2025 22:41:46 - INFO - __main__ -   epoch 5 step 5700 loss 0.02108\n",
            "03/18/2025 22:42:31 - INFO - __main__ -   epoch 5 step 5800 loss 0.02767\n",
            "03/18/2025 22:43:15 - INFO - __main__ -   epoch 5 step 5900 loss 0.02429\n",
            "03/18/2025 22:43:59 - INFO - __main__ -   epoch 5 step 6000 loss 0.02261\n",
            "03/18/2025 22:44:43 - INFO - __main__ -   epoch 5 step 6100 loss 0.02295\n",
            "03/18/2025 22:45:28 - INFO - __main__ -   epoch 5 step 6200 loss 0.03135\n",
            "03/18/2025 22:46:12 - INFO - __main__ -   epoch 5 step 6300 loss 0.02635\n",
            "03/18/2025 22:46:56 - INFO - __main__ -   epoch 5 step 6400 loss 0.03302\n",
            "03/18/2025 22:47:40 - INFO - __main__ -   epoch 5 step 6500 loss 0.02484\n",
            "03/18/2025 22:48:25 - INFO - __main__ -   epoch 5 step 6600 loss 0.02291\n",
            "03/18/2025 22:49:09 - INFO - __main__ -   epoch 5 step 6700 loss 0.03201\n",
            "03/18/2025 22:49:53 - INFO - __main__ -   epoch 5 step 6800 loss 0.03722\n",
            "03/18/2025 22:50:37 - INFO - __main__ -   epoch 5 step 6900 loss 0.01912\n",
            "03/18/2025 22:51:22 - INFO - __main__ -   epoch 5 step 7000 loss 0.03519\n",
            "03/18/2025 22:52:06 - INFO - __main__ -   epoch 5 step 7100 loss 0.03335\n",
            "03/18/2025 22:52:50 - INFO - __main__ -   epoch 5 step 7200 loss 0.03236\n",
            "03/18/2025 22:53:34 - INFO - __main__ -   epoch 5 step 7300 loss 0.02551\n",
            "03/18/2025 22:54:19 - INFO - __main__ -   epoch 5 step 7400 loss 0.01923\n",
            "03/18/2025 22:55:03 - INFO - __main__ -   epoch 5 step 7500 loss 0.02014\n",
            "03/18/2025 22:55:47 - INFO - __main__ -   epoch 5 step 7600 loss 0.02846\n",
            "03/18/2025 22:56:31 - INFO - __main__ -   epoch 5 step 7700 loss 0.03088\n",
            "03/18/2025 22:57:16 - INFO - __main__ -   epoch 5 step 7800 loss 0.03929\n",
            "03/18/2025 22:58:32 - INFO - __main__ -   ***** Running evaluation *****\n",
            "03/18/2025 22:58:32 - INFO - __main__ -     Num queries = 13914\n",
            "03/18/2025 22:58:32 - INFO - __main__ -     Num codes = 43827\n",
            "03/18/2025 22:58:32 - INFO - __main__ -     Batch size = 64\n",
            "03/18/2025 23:01:08 - INFO - __main__ -     Success@1 = 0.0\n",
            "03/18/2025 23:01:08 - INFO - __main__ -     Success@5 = 0.0001\n",
            "03/18/2025 23:01:08 - INFO - __main__ -     Success@10 = 0.0004\n",
            "03/18/2025 23:01:08 - INFO - __main__ -     MRR = 0.6365\n",
            "03/18/2025 23:01:08 - INFO - __main__ -     ********************\n",
            "03/18/2025 23:01:08 - INFO - __main__ -     Best mrr:0.6365\n",
            "03/18/2025 23:01:08 - INFO - __main__ -     ********************\n",
            "03/18/2025 23:01:10 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/CoSHC/CodeBERT/models/python/checkpoint-best-mrr/model.bin\n",
            "03/18/2025 23:01:55 - INFO - __main__ -   epoch 6 step 100 loss 0.03065\n",
            "03/18/2025 23:02:39 - INFO - __main__ -   epoch 6 step 200 loss 0.01539\n",
            "03/18/2025 23:03:23 - INFO - __main__ -   epoch 6 step 300 loss 0.02165\n",
            "03/18/2025 23:04:07 - INFO - __main__ -   epoch 6 step 400 loss 0.02386\n",
            "03/18/2025 23:04:51 - INFO - __main__ -   epoch 6 step 500 loss 0.02332\n",
            "03/18/2025 23:05:36 - INFO - __main__ -   epoch 6 step 600 loss 0.01647\n",
            "03/18/2025 23:06:20 - INFO - __main__ -   epoch 6 step 700 loss 0.03393\n",
            "03/18/2025 23:07:04 - INFO - __main__ -   epoch 6 step 800 loss 0.02183\n",
            "03/18/2025 23:07:48 - INFO - __main__ -   epoch 6 step 900 loss 0.02543\n",
            "03/18/2025 23:08:33 - INFO - __main__ -   epoch 6 step 1000 loss 0.0371\n",
            "03/18/2025 23:09:19 - INFO - __main__ -   epoch 6 step 1100 loss 0.01259\n",
            "03/18/2025 23:10:03 - INFO - __main__ -   epoch 6 step 1200 loss 0.01891\n",
            "03/18/2025 23:10:47 - INFO - __main__ -   epoch 6 step 1300 loss 0.02346\n",
            "03/18/2025 23:11:32 - INFO - __main__ -   epoch 6 step 1400 loss 0.01838\n",
            "03/18/2025 23:12:16 - INFO - __main__ -   epoch 6 step 1500 loss 0.02557\n",
            "03/18/2025 23:13:00 - INFO - __main__ -   epoch 6 step 1600 loss 0.02868\n",
            "03/18/2025 23:13:44 - INFO - __main__ -   epoch 6 step 1700 loss 0.02219\n",
            "03/18/2025 23:14:28 - INFO - __main__ -   epoch 6 step 1800 loss 0.02797\n",
            "03/18/2025 23:15:12 - INFO - __main__ -   epoch 6 step 1900 loss 0.02931\n",
            "03/18/2025 23:15:57 - INFO - __main__ -   epoch 6 step 2000 loss 0.01726\n",
            "03/18/2025 23:16:41 - INFO - __main__ -   epoch 6 step 2100 loss 0.02091\n",
            "03/18/2025 23:17:25 - INFO - __main__ -   epoch 6 step 2200 loss 0.03638\n",
            "03/18/2025 23:18:09 - INFO - __main__ -   epoch 6 step 2300 loss 0.02949\n",
            "03/18/2025 23:18:53 - INFO - __main__ -   epoch 6 step 2400 loss 0.01865\n",
            "03/18/2025 23:19:37 - INFO - __main__ -   epoch 6 step 2500 loss 0.02703\n",
            "03/18/2025 23:20:22 - INFO - __main__ -   epoch 6 step 2600 loss 0.02195\n",
            "03/18/2025 23:21:06 - INFO - __main__ -   epoch 6 step 2700 loss 0.02439\n",
            "03/18/2025 23:21:50 - INFO - __main__ -   epoch 6 step 2800 loss 0.02509\n",
            "03/18/2025 23:22:34 - INFO - __main__ -   epoch 6 step 2900 loss 0.02842\n",
            "03/18/2025 23:23:19 - INFO - __main__ -   epoch 6 step 3000 loss 0.02573\n",
            "03/18/2025 23:24:03 - INFO - __main__ -   epoch 6 step 3100 loss 0.03484\n",
            "03/18/2025 23:24:47 - INFO - __main__ -   epoch 6 step 3200 loss 0.02883\n",
            "03/18/2025 23:25:31 - INFO - __main__ -   epoch 6 step 3300 loss 0.0201\n",
            "03/18/2025 23:26:16 - INFO - __main__ -   epoch 6 step 3400 loss 0.03515\n",
            "03/18/2025 23:27:00 - INFO - __main__ -   epoch 6 step 3500 loss 0.02136\n",
            "03/18/2025 23:27:44 - INFO - __main__ -   epoch 6 step 3600 loss 0.02411\n",
            "03/18/2025 23:28:28 - INFO - __main__ -   epoch 6 step 3700 loss 0.02281\n",
            "03/18/2025 23:29:13 - INFO - __main__ -   epoch 6 step 3800 loss 0.0159\n",
            "03/18/2025 23:29:57 - INFO - __main__ -   epoch 6 step 3900 loss 0.02859\n",
            "03/18/2025 23:30:41 - INFO - __main__ -   epoch 6 step 4000 loss 0.02307\n",
            "03/18/2025 23:31:25 - INFO - __main__ -   epoch 6 step 4100 loss 0.02352\n",
            "03/18/2025 23:32:10 - INFO - __main__ -   epoch 6 step 4200 loss 0.02085\n",
            "03/18/2025 23:32:54 - INFO - __main__ -   epoch 6 step 4300 loss 0.02946\n",
            "03/18/2025 23:33:38 - INFO - __main__ -   epoch 6 step 4400 loss 0.02119\n",
            "03/18/2025 23:34:22 - INFO - __main__ -   epoch 6 step 4500 loss 0.01564\n",
            "03/18/2025 23:35:06 - INFO - __main__ -   epoch 6 step 4600 loss 0.01718\n",
            "03/18/2025 23:35:50 - INFO - __main__ -   epoch 6 step 4700 loss 0.02379\n",
            "03/18/2025 23:36:35 - INFO - __main__ -   epoch 6 step 4800 loss 0.01915\n",
            "03/18/2025 23:37:19 - INFO - __main__ -   epoch 6 step 4900 loss 0.02851\n",
            "03/18/2025 23:38:03 - INFO - __main__ -   epoch 6 step 5000 loss 0.02679\n",
            "03/18/2025 23:38:47 - INFO - __main__ -   epoch 6 step 5100 loss 0.04235\n",
            "03/18/2025 23:39:31 - INFO - __main__ -   epoch 6 step 5200 loss 0.01998\n",
            "03/18/2025 23:40:16 - INFO - __main__ -   epoch 6 step 5300 loss 0.02484\n",
            "03/18/2025 23:41:00 - INFO - __main__ -   epoch 6 step 5400 loss 0.02265\n",
            "03/18/2025 23:41:44 - INFO - __main__ -   epoch 6 step 5500 loss 0.01815\n",
            "03/18/2025 23:42:28 - INFO - __main__ -   epoch 6 step 5600 loss 0.02461\n",
            "03/18/2025 23:43:12 - INFO - __main__ -   epoch 6 step 5700 loss 0.02005\n",
            "03/18/2025 23:43:56 - INFO - __main__ -   epoch 6 step 5800 loss 0.0266\n",
            "03/18/2025 23:44:41 - INFO - __main__ -   epoch 6 step 5900 loss 0.02337\n",
            "03/18/2025 23:45:25 - INFO - __main__ -   epoch 6 step 6000 loss 0.02403\n",
            "03/18/2025 23:46:09 - INFO - __main__ -   epoch 6 step 6100 loss 0.01821\n",
            "03/18/2025 23:46:53 - INFO - __main__ -   epoch 6 step 6200 loss 0.01908\n",
            "03/18/2025 23:47:37 - INFO - __main__ -   epoch 6 step 6300 loss 0.01934\n",
            "03/18/2025 23:48:22 - INFO - __main__ -   epoch 6 step 6400 loss 0.03642\n",
            "03/18/2025 23:49:06 - INFO - __main__ -   epoch 6 step 6500 loss 0.02338\n",
            "03/18/2025 23:49:50 - INFO - __main__ -   epoch 6 step 6600 loss 0.02597\n",
            "03/18/2025 23:50:34 - INFO - __main__ -   epoch 6 step 6700 loss 0.01807\n",
            "03/18/2025 23:51:18 - INFO - __main__ -   epoch 6 step 6800 loss 0.03064\n",
            "03/18/2025 23:52:03 - INFO - __main__ -   epoch 6 step 6900 loss 0.0236\n",
            "03/18/2025 23:52:47 - INFO - __main__ -   epoch 6 step 7000 loss 0.01857\n",
            "03/18/2025 23:53:31 - INFO - __main__ -   epoch 6 step 7100 loss 0.0142\n",
            "03/18/2025 23:54:15 - INFO - __main__ -   epoch 6 step 7200 loss 0.01894\n",
            "03/18/2025 23:55:00 - INFO - __main__ -   epoch 6 step 7300 loss 0.02293\n",
            "03/18/2025 23:55:44 - INFO - __main__ -   epoch 6 step 7400 loss 0.01756\n",
            "03/18/2025 23:56:28 - INFO - __main__ -   epoch 6 step 7500 loss 0.02075\n",
            "03/18/2025 23:57:12 - INFO - __main__ -   epoch 6 step 7600 loss 0.01902\n",
            "03/18/2025 23:57:56 - INFO - __main__ -   epoch 6 step 7700 loss 0.0297\n",
            "03/18/2025 23:58:41 - INFO - __main__ -   epoch 6 step 7800 loss 0.02973\n",
            "03/18/2025 23:59:57 - INFO - __main__ -   ***** Running evaluation *****\n",
            "03/18/2025 23:59:57 - INFO - __main__ -     Num queries = 13914\n",
            "03/18/2025 23:59:57 - INFO - __main__ -     Num codes = 43827\n",
            "03/18/2025 23:59:57 - INFO - __main__ -     Batch size = 64\n",
            "03/19/2025 00:02:33 - INFO - __main__ -     Success@1 = 0.0\n",
            "03/19/2025 00:02:33 - INFO - __main__ -     Success@5 = 0.0001\n",
            "03/19/2025 00:02:33 - INFO - __main__ -     Success@10 = 0.0004\n",
            "03/19/2025 00:02:33 - INFO - __main__ -     MRR = 0.6404\n",
            "03/19/2025 00:02:33 - INFO - __main__ -     ********************\n",
            "03/19/2025 00:02:33 - INFO - __main__ -     Best mrr:0.6404\n",
            "03/19/2025 00:02:33 - INFO - __main__ -     ********************\n",
            "03/19/2025 00:02:35 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/CoSHC/CodeBERT/models/python/checkpoint-best-mrr/model.bin\n",
            "03/19/2025 00:03:20 - INFO - __main__ -   epoch 7 step 100 loss 0.02533\n",
            "03/19/2025 00:04:04 - INFO - __main__ -   epoch 7 step 200 loss 0.02968\n",
            "03/19/2025 00:04:48 - INFO - __main__ -   epoch 7 step 300 loss 0.01776\n",
            "03/19/2025 00:05:32 - INFO - __main__ -   epoch 7 step 400 loss 0.01028\n",
            "03/19/2025 00:06:16 - INFO - __main__ -   epoch 7 step 500 loss 0.01667\n",
            "03/19/2025 00:07:01 - INFO - __main__ -   epoch 7 step 600 loss 0.01801\n",
            "03/19/2025 00:07:45 - INFO - __main__ -   epoch 7 step 700 loss 0.01707\n",
            "03/19/2025 00:08:29 - INFO - __main__ -   epoch 7 step 800 loss 0.0203\n",
            "03/19/2025 00:09:13 - INFO - __main__ -   epoch 7 step 900 loss 0.0232\n",
            "03/19/2025 00:09:57 - INFO - __main__ -   epoch 7 step 1000 loss 0.03717\n",
            "03/19/2025 00:10:41 - INFO - __main__ -   epoch 7 step 1100 loss 0.01962\n",
            "03/19/2025 00:11:26 - INFO - __main__ -   epoch 7 step 1200 loss 0.02205\n",
            "03/19/2025 00:12:10 - INFO - __main__ -   epoch 7 step 1300 loss 0.01844\n",
            "03/19/2025 00:12:54 - INFO - __main__ -   epoch 7 step 1400 loss 0.01906\n",
            "03/19/2025 00:13:40 - INFO - __main__ -   epoch 7 step 1500 loss 0.03332\n",
            "03/19/2025 00:14:25 - INFO - __main__ -   epoch 7 step 1600 loss 0.0209\n",
            "03/19/2025 00:15:09 - INFO - __main__ -   epoch 7 step 1700 loss 0.01344\n",
            "03/19/2025 00:15:53 - INFO - __main__ -   epoch 7 step 1800 loss 0.02116\n",
            "03/19/2025 00:16:37 - INFO - __main__ -   epoch 7 step 1900 loss 0.01894\n",
            "03/19/2025 00:17:21 - INFO - __main__ -   epoch 7 step 2000 loss 0.01705\n",
            "03/19/2025 00:18:05 - INFO - __main__ -   epoch 7 step 2100 loss 0.01431\n",
            "03/19/2025 00:18:50 - INFO - __main__ -   epoch 7 step 2200 loss 0.01751\n",
            "03/19/2025 00:19:34 - INFO - __main__ -   epoch 7 step 2300 loss 0.01524\n",
            "03/19/2025 00:20:18 - INFO - __main__ -   epoch 7 step 2400 loss 0.01211\n",
            "03/19/2025 00:21:02 - INFO - __main__ -   epoch 7 step 2500 loss 0.02874\n",
            "03/19/2025 00:21:46 - INFO - __main__ -   epoch 7 step 2600 loss 0.0294\n",
            "03/19/2025 00:22:31 - INFO - __main__ -   epoch 7 step 2700 loss 0.02603\n",
            "03/19/2025 00:23:15 - INFO - __main__ -   epoch 7 step 2800 loss 0.02006\n",
            "03/19/2025 00:23:59 - INFO - __main__ -   epoch 7 step 2900 loss 0.01538\n",
            "03/19/2025 00:24:43 - INFO - __main__ -   epoch 7 step 3000 loss 0.02264\n",
            "03/19/2025 00:25:27 - INFO - __main__ -   epoch 7 step 3100 loss 0.0143\n",
            "03/19/2025 00:26:11 - INFO - __main__ -   epoch 7 step 3200 loss 0.01877\n",
            "03/19/2025 00:26:56 - INFO - __main__ -   epoch 7 step 3300 loss 0.02294\n",
            "03/19/2025 00:27:40 - INFO - __main__ -   epoch 7 step 3400 loss 0.02137\n",
            "03/19/2025 00:28:24 - INFO - __main__ -   epoch 7 step 3500 loss 0.02344\n",
            "03/19/2025 00:29:08 - INFO - __main__ -   epoch 7 step 3600 loss 0.027\n",
            "03/19/2025 00:29:52 - INFO - __main__ -   epoch 7 step 3700 loss 0.01891\n",
            "03/19/2025 00:30:36 - INFO - __main__ -   epoch 7 step 3800 loss 0.01822\n",
            "03/19/2025 00:31:21 - INFO - __main__ -   epoch 7 step 3900 loss 0.01371\n",
            "03/19/2025 00:32:05 - INFO - __main__ -   epoch 7 step 4000 loss 0.01246\n",
            "03/19/2025 00:32:49 - INFO - __main__ -   epoch 7 step 4100 loss 0.01458\n",
            "03/19/2025 00:33:33 - INFO - __main__ -   epoch 7 step 4200 loss 0.02082\n",
            "03/19/2025 00:34:17 - INFO - __main__ -   epoch 7 step 4300 loss 0.02341\n",
            "03/19/2025 00:35:02 - INFO - __main__ -   epoch 7 step 4400 loss 0.01888\n",
            "03/19/2025 00:35:46 - INFO - __main__ -   epoch 7 step 4500 loss 0.04397\n",
            "03/19/2025 00:36:30 - INFO - __main__ -   epoch 7 step 4600 loss 0.02513\n",
            "03/19/2025 00:37:14 - INFO - __main__ -   epoch 7 step 4700 loss 0.01911\n",
            "03/19/2025 00:37:59 - INFO - __main__ -   epoch 7 step 4800 loss 0.03149\n",
            "03/19/2025 00:38:43 - INFO - __main__ -   epoch 7 step 4900 loss 0.01018\n",
            "03/19/2025 00:39:27 - INFO - __main__ -   epoch 7 step 5000 loss 0.01166\n",
            "03/19/2025 00:40:11 - INFO - __main__ -   epoch 7 step 5100 loss 0.02659\n",
            "03/19/2025 00:40:55 - INFO - __main__ -   epoch 7 step 5200 loss 0.02767\n",
            "03/19/2025 00:41:39 - INFO - __main__ -   epoch 7 step 5300 loss 0.02416\n",
            "03/19/2025 00:42:24 - INFO - __main__ -   epoch 7 step 5400 loss 0.02547\n",
            "03/19/2025 00:43:08 - INFO - __main__ -   epoch 7 step 5500 loss 0.02295\n",
            "03/19/2025 00:43:52 - INFO - __main__ -   epoch 7 step 5600 loss 0.01275\n",
            "03/19/2025 00:44:36 - INFO - __main__ -   epoch 7 step 5700 loss 0.00976\n",
            "03/19/2025 00:45:20 - INFO - __main__ -   epoch 7 step 5800 loss 0.01802\n",
            "03/19/2025 00:46:05 - INFO - __main__ -   epoch 7 step 5900 loss 0.01013\n",
            "03/19/2025 00:46:49 - INFO - __main__ -   epoch 7 step 6000 loss 0.02643\n",
            "03/19/2025 00:47:33 - INFO - __main__ -   epoch 7 step 6100 loss 0.01825\n",
            "03/19/2025 00:48:17 - INFO - __main__ -   epoch 7 step 6200 loss 0.03192\n",
            "03/19/2025 00:49:01 - INFO - __main__ -   epoch 7 step 6300 loss 0.03878\n",
            "03/19/2025 00:49:45 - INFO - __main__ -   epoch 7 step 6400 loss 0.02275\n",
            "03/19/2025 00:50:30 - INFO - __main__ -   epoch 7 step 6500 loss 0.01602\n",
            "03/19/2025 00:51:14 - INFO - __main__ -   epoch 7 step 6600 loss 0.01417\n",
            "03/19/2025 00:51:58 - INFO - __main__ -   epoch 7 step 6700 loss 0.02653\n",
            "03/19/2025 00:52:42 - INFO - __main__ -   epoch 7 step 6800 loss 0.013\n",
            "03/19/2025 00:53:26 - INFO - __main__ -   epoch 7 step 6900 loss 0.01274\n",
            "03/19/2025 00:54:10 - INFO - __main__ -   epoch 7 step 7000 loss 0.01644\n",
            "03/19/2025 00:54:55 - INFO - __main__ -   epoch 7 step 7100 loss 0.02354\n",
            "03/19/2025 00:55:39 - INFO - __main__ -   epoch 7 step 7200 loss 0.01242\n",
            "03/19/2025 00:56:23 - INFO - __main__ -   epoch 7 step 7300 loss 0.03154\n",
            "03/19/2025 00:57:07 - INFO - __main__ -   epoch 7 step 7400 loss 0.01472\n",
            "03/19/2025 00:57:51 - INFO - __main__ -   epoch 7 step 7500 loss 0.01124\n",
            "03/19/2025 00:58:35 - INFO - __main__ -   epoch 7 step 7600 loss 0.0184\n",
            "03/19/2025 00:59:20 - INFO - __main__ -   epoch 7 step 7700 loss 0.01483\n",
            "03/19/2025 01:00:04 - INFO - __main__ -   epoch 7 step 7800 loss 0.01649\n",
            "03/19/2025 01:01:20 - INFO - __main__ -   ***** Running evaluation *****\n",
            "03/19/2025 01:01:20 - INFO - __main__ -     Num queries = 13914\n",
            "03/19/2025 01:01:20 - INFO - __main__ -     Num codes = 43827\n",
            "03/19/2025 01:01:20 - INFO - __main__ -     Batch size = 64\n",
            "03/19/2025 01:03:55 - INFO - __main__ -     Success@1 = 0.0\n",
            "03/19/2025 01:03:55 - INFO - __main__ -     Success@5 = 0.0001\n",
            "03/19/2025 01:03:55 - INFO - __main__ -     Success@10 = 0.0004\n",
            "03/19/2025 01:03:55 - INFO - __main__ -     MRR = 0.6472\n",
            "03/19/2025 01:03:55 - INFO - __main__ -     ********************\n",
            "03/19/2025 01:03:55 - INFO - __main__ -     Best mrr:0.6472\n",
            "03/19/2025 01:03:55 - INFO - __main__ -     ********************\n",
            "03/19/2025 01:03:58 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/CoSHC/CodeBERT/models/python/checkpoint-best-mrr/model.bin\n",
            "03/19/2025 01:04:42 - INFO - __main__ -   epoch 8 step 100 loss 0.01589\n",
            "03/19/2025 01:05:26 - INFO - __main__ -   epoch 8 step 200 loss 0.02454\n",
            "03/19/2025 01:06:11 - INFO - __main__ -   epoch 8 step 300 loss 0.0151\n",
            "03/19/2025 01:06:55 - INFO - __main__ -   epoch 8 step 400 loss 0.02247\n",
            "03/19/2025 01:07:39 - INFO - __main__ -   epoch 8 step 500 loss 0.01307\n",
            "03/19/2025 01:08:23 - INFO - __main__ -   epoch 8 step 600 loss 0.01962\n",
            "03/19/2025 01:09:07 - INFO - __main__ -   epoch 8 step 700 loss 0.01805\n",
            "03/19/2025 01:09:51 - INFO - __main__ -   epoch 8 step 800 loss 0.01447\n",
            "03/19/2025 01:10:35 - INFO - __main__ -   epoch 8 step 900 loss 0.01424\n",
            "03/19/2025 01:11:20 - INFO - __main__ -   epoch 8 step 1000 loss 0.01576\n",
            "03/19/2025 01:12:04 - INFO - __main__ -   epoch 8 step 1100 loss 0.0112\n",
            "03/19/2025 01:12:48 - INFO - __main__ -   epoch 8 step 1200 loss 0.01022\n",
            "03/19/2025 01:13:32 - INFO - __main__ -   epoch 8 step 1300 loss 0.01926\n",
            "03/19/2025 01:14:16 - INFO - __main__ -   epoch 8 step 1400 loss 0.01266\n",
            "03/19/2025 01:15:00 - INFO - __main__ -   epoch 8 step 1500 loss 0.02841\n",
            "03/19/2025 01:15:44 - INFO - __main__ -   epoch 8 step 1600 loss 0.0158\n",
            "03/19/2025 01:16:29 - INFO - __main__ -   epoch 8 step 1700 loss 0.01031\n",
            "03/19/2025 01:17:13 - INFO - __main__ -   epoch 8 step 1800 loss 0.01267\n",
            "03/19/2025 01:17:59 - INFO - __main__ -   epoch 8 step 1900 loss 0.01346\n",
            "03/19/2025 01:18:43 - INFO - __main__ -   epoch 8 step 2000 loss 0.02417\n",
            "03/19/2025 01:19:27 - INFO - __main__ -   epoch 8 step 2100 loss 0.01609\n",
            "03/19/2025 01:20:11 - INFO - __main__ -   epoch 8 step 2200 loss 0.01676\n",
            "03/19/2025 01:20:56 - INFO - __main__ -   epoch 8 step 2300 loss 0.01951\n",
            "03/19/2025 01:21:40 - INFO - __main__ -   epoch 8 step 2400 loss 0.00722\n",
            "03/19/2025 01:22:24 - INFO - __main__ -   epoch 8 step 2500 loss 0.01046\n",
            "03/19/2025 01:23:08 - INFO - __main__ -   epoch 8 step 2600 loss 0.01557\n",
            "03/19/2025 01:23:52 - INFO - __main__ -   epoch 8 step 2700 loss 0.02077\n",
            "03/19/2025 01:24:36 - INFO - __main__ -   epoch 8 step 2800 loss 0.01125\n",
            "03/19/2025 01:25:20 - INFO - __main__ -   epoch 8 step 2900 loss 0.01492\n",
            "03/19/2025 01:26:05 - INFO - __main__ -   epoch 8 step 3000 loss 0.01617\n",
            "03/19/2025 01:26:49 - INFO - __main__ -   epoch 8 step 3100 loss 0.01283\n",
            "03/19/2025 01:27:33 - INFO - __main__ -   epoch 8 step 3200 loss 0.01791\n",
            "03/19/2025 01:28:17 - INFO - __main__ -   epoch 8 step 3300 loss 0.01385\n",
            "03/19/2025 01:29:01 - INFO - __main__ -   epoch 8 step 3400 loss 0.01762\n",
            "03/19/2025 01:29:45 - INFO - __main__ -   epoch 8 step 3500 loss 0.01596\n",
            "03/19/2025 01:30:29 - INFO - __main__ -   epoch 8 step 3600 loss 0.01488\n",
            "03/19/2025 01:31:14 - INFO - __main__ -   epoch 8 step 3700 loss 0.0211\n",
            "03/19/2025 01:31:58 - INFO - __main__ -   epoch 8 step 3800 loss 0.01446\n",
            "03/19/2025 01:32:42 - INFO - __main__ -   epoch 8 step 3900 loss 0.01171\n",
            "03/19/2025 01:33:26 - INFO - __main__ -   epoch 8 step 4000 loss 0.02053\n",
            "03/19/2025 01:34:10 - INFO - __main__ -   epoch 8 step 4100 loss 0.01304\n",
            "03/19/2025 01:34:54 - INFO - __main__ -   epoch 8 step 4200 loss 0.01491\n",
            "03/19/2025 01:35:38 - INFO - __main__ -   epoch 8 step 4300 loss 0.02553\n",
            "03/19/2025 01:36:22 - INFO - __main__ -   epoch 8 step 4400 loss 0.00992\n",
            "03/19/2025 01:37:07 - INFO - __main__ -   epoch 8 step 4500 loss 0.01095\n",
            "03/19/2025 01:37:51 - INFO - __main__ -   epoch 8 step 4600 loss 0.015\n",
            "03/19/2025 01:38:35 - INFO - __main__ -   epoch 8 step 4700 loss 0.01638\n",
            "03/19/2025 01:39:19 - INFO - __main__ -   epoch 8 step 4800 loss 0.02729\n",
            "03/19/2025 01:40:03 - INFO - __main__ -   epoch 8 step 4900 loss 0.02276\n",
            "03/19/2025 01:40:47 - INFO - __main__ -   epoch 8 step 5000 loss 0.01985\n",
            "03/19/2025 01:41:31 - INFO - __main__ -   epoch 8 step 5100 loss 0.01514\n",
            "03/19/2025 01:42:16 - INFO - __main__ -   epoch 8 step 5200 loss 0.01673\n",
            "03/19/2025 01:43:00 - INFO - __main__ -   epoch 8 step 5300 loss 0.01595\n",
            "03/19/2025 01:43:44 - INFO - __main__ -   epoch 8 step 5400 loss 0.01161\n",
            "03/19/2025 01:44:28 - INFO - __main__ -   epoch 8 step 5500 loss 0.02745\n",
            "03/19/2025 01:45:12 - INFO - __main__ -   epoch 8 step 5600 loss 0.00962\n",
            "03/19/2025 01:45:56 - INFO - __main__ -   epoch 8 step 5700 loss 0.0224\n",
            "03/19/2025 01:46:40 - INFO - __main__ -   epoch 8 step 5800 loss 0.01341\n",
            "03/19/2025 01:47:25 - INFO - __main__ -   epoch 8 step 5900 loss 0.01563\n",
            "03/19/2025 01:48:09 - INFO - __main__ -   epoch 8 step 6000 loss 0.01267\n",
            "03/19/2025 01:48:53 - INFO - __main__ -   epoch 8 step 6100 loss 0.01348\n",
            "03/19/2025 01:49:37 - INFO - __main__ -   epoch 8 step 6200 loss 0.01719\n",
            "03/19/2025 01:50:21 - INFO - __main__ -   epoch 8 step 6300 loss 0.01012\n",
            "03/19/2025 01:51:05 - INFO - __main__ -   epoch 8 step 6400 loss 0.01254\n",
            "03/19/2025 01:51:49 - INFO - __main__ -   epoch 8 step 6500 loss 0.01391\n",
            "03/19/2025 01:52:34 - INFO - __main__ -   epoch 8 step 6600 loss 0.01095\n",
            "03/19/2025 01:53:18 - INFO - __main__ -   epoch 8 step 6700 loss 0.01293\n",
            "03/19/2025 01:54:02 - INFO - __main__ -   epoch 8 step 6800 loss 0.01769\n",
            "03/19/2025 01:54:46 - INFO - __main__ -   epoch 8 step 6900 loss 0.01649\n",
            "03/19/2025 01:55:30 - INFO - __main__ -   epoch 8 step 7000 loss 0.01369\n",
            "03/19/2025 01:56:14 - INFO - __main__ -   epoch 8 step 7100 loss 0.00872\n",
            "03/19/2025 01:56:58 - INFO - __main__ -   epoch 8 step 7200 loss 0.00669\n",
            "03/19/2025 01:57:43 - INFO - __main__ -   epoch 8 step 7300 loss 0.01324\n",
            "03/19/2025 01:58:27 - INFO - __main__ -   epoch 8 step 7400 loss 0.01535\n",
            "03/19/2025 01:59:11 - INFO - __main__ -   epoch 8 step 7500 loss 0.01836\n",
            "03/19/2025 01:59:55 - INFO - __main__ -   epoch 8 step 7600 loss 0.00991\n",
            "03/19/2025 02:00:39 - INFO - __main__ -   epoch 8 step 7700 loss 0.01263\n",
            "03/19/2025 02:01:23 - INFO - __main__ -   epoch 8 step 7800 loss 0.01785\n",
            "03/19/2025 02:02:39 - INFO - __main__ -   ***** Running evaluation *****\n",
            "03/19/2025 02:02:39 - INFO - __main__ -     Num queries = 13914\n",
            "03/19/2025 02:02:39 - INFO - __main__ -     Num codes = 43827\n",
            "03/19/2025 02:02:39 - INFO - __main__ -     Batch size = 64\n",
            "03/19/2025 02:05:15 - INFO - __main__ -     Success@1 = 0.0\n",
            "03/19/2025 02:05:15 - INFO - __main__ -     Success@5 = 0.0001\n",
            "03/19/2025 02:05:15 - INFO - __main__ -     Success@10 = 0.0004\n",
            "03/19/2025 02:05:15 - INFO - __main__ -     MRR = 0.6505\n",
            "03/19/2025 02:05:15 - INFO - __main__ -     ********************\n",
            "03/19/2025 02:05:15 - INFO - __main__ -     Best mrr:0.6505\n",
            "03/19/2025 02:05:15 - INFO - __main__ -     ********************\n",
            "03/19/2025 02:05:17 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/CoSHC/CodeBERT/models/python/checkpoint-best-mrr/model.bin\n",
            "03/19/2025 02:06:02 - INFO - __main__ -   epoch 9 step 100 loss 0.01445\n",
            "03/19/2025 02:06:46 - INFO - __main__ -   epoch 9 step 200 loss 0.0176\n",
            "03/19/2025 02:07:30 - INFO - __main__ -   epoch 9 step 300 loss 0.01151\n",
            "03/19/2025 02:08:14 - INFO - __main__ -   epoch 9 step 400 loss 0.00896\n",
            "03/19/2025 02:08:58 - INFO - __main__ -   epoch 9 step 500 loss 0.0184\n",
            "03/19/2025 02:09:42 - INFO - __main__ -   epoch 9 step 600 loss 0.01285\n",
            "03/19/2025 02:10:26 - INFO - __main__ -   epoch 9 step 700 loss 0.0135\n",
            "03/19/2025 02:11:11 - INFO - __main__ -   epoch 9 step 800 loss 0.0139\n",
            "03/19/2025 02:11:55 - INFO - __main__ -   epoch 9 step 900 loss 0.00951\n",
            "03/19/2025 02:12:39 - INFO - __main__ -   epoch 9 step 1000 loss 0.01787\n",
            "03/19/2025 02:13:23 - INFO - __main__ -   epoch 9 step 1100 loss 0.02448\n",
            "03/19/2025 02:14:07 - INFO - __main__ -   epoch 9 step 1200 loss 0.01568\n",
            "03/19/2025 02:14:51 - INFO - __main__ -   epoch 9 step 1300 loss 0.00795\n",
            "03/19/2025 02:15:35 - INFO - __main__ -   epoch 9 step 1400 loss 0.0171\n",
            "03/19/2025 02:16:20 - INFO - __main__ -   epoch 9 step 1500 loss 0.02964\n",
            "03/19/2025 02:17:04 - INFO - __main__ -   epoch 9 step 1600 loss 0.01322\n",
            "03/19/2025 02:17:48 - INFO - __main__ -   epoch 9 step 1700 loss 0.01354\n",
            "03/19/2025 02:18:32 - INFO - __main__ -   epoch 9 step 1800 loss 0.01631\n",
            "03/19/2025 02:19:16 - INFO - __main__ -   epoch 9 step 1900 loss 0.0126\n",
            "03/19/2025 02:20:00 - INFO - __main__ -   epoch 9 step 2000 loss 0.01561\n",
            "03/19/2025 02:20:45 - INFO - __main__ -   epoch 9 step 2100 loss 0.00981\n",
            "03/19/2025 02:21:29 - INFO - __main__ -   epoch 9 step 2200 loss 0.01135\n",
            "03/19/2025 02:22:13 - INFO - __main__ -   epoch 9 step 2300 loss 0.02048\n",
            "03/19/2025 02:22:59 - INFO - __main__ -   epoch 9 step 2400 loss 0.01137\n",
            "03/19/2025 02:23:43 - INFO - __main__ -   epoch 9 step 2500 loss 0.01208\n",
            "03/19/2025 02:24:27 - INFO - __main__ -   epoch 9 step 2600 loss 0.01836\n",
            "03/19/2025 02:25:12 - INFO - __main__ -   epoch 9 step 2700 loss 0.01514\n",
            "03/19/2025 02:25:56 - INFO - __main__ -   epoch 9 step 2800 loss 0.01081\n",
            "03/19/2025 02:26:40 - INFO - __main__ -   epoch 9 step 2900 loss 0.02049\n",
            "03/19/2025 02:27:24 - INFO - __main__ -   epoch 9 step 3000 loss 0.01747\n",
            "03/19/2025 02:28:08 - INFO - __main__ -   epoch 9 step 3100 loss 0.01613\n",
            "03/19/2025 02:28:52 - INFO - __main__ -   epoch 9 step 3200 loss 0.01279\n",
            "03/19/2025 02:29:36 - INFO - __main__ -   epoch 9 step 3300 loss 0.01877\n",
            "03/19/2025 02:30:21 - INFO - __main__ -   epoch 9 step 3400 loss 0.00969\n",
            "03/19/2025 02:31:05 - INFO - __main__ -   epoch 9 step 3500 loss 0.02005\n",
            "03/19/2025 02:31:49 - INFO - __main__ -   epoch 9 step 3600 loss 0.01599\n",
            "03/19/2025 02:32:33 - INFO - __main__ -   epoch 9 step 3700 loss 0.01899\n",
            "03/19/2025 02:33:17 - INFO - __main__ -   epoch 9 step 3800 loss 0.00781\n",
            "03/19/2025 02:34:01 - INFO - __main__ -   epoch 9 step 3900 loss 0.01567\n",
            "03/19/2025 02:34:45 - INFO - __main__ -   epoch 9 step 4000 loss 0.03068\n",
            "03/19/2025 02:35:30 - INFO - __main__ -   epoch 9 step 4100 loss 0.01646\n",
            "03/19/2025 02:36:14 - INFO - __main__ -   epoch 9 step 4200 loss 0.01463\n",
            "03/19/2025 02:36:58 - INFO - __main__ -   epoch 9 step 4300 loss 0.01215\n",
            "03/19/2025 02:37:42 - INFO - __main__ -   epoch 9 step 4400 loss 0.02304\n",
            "03/19/2025 02:38:26 - INFO - __main__ -   epoch 9 step 4500 loss 0.01515\n",
            "03/19/2025 02:39:10 - INFO - __main__ -   epoch 9 step 4600 loss 0.01187\n",
            "03/19/2025 02:39:54 - INFO - __main__ -   epoch 9 step 4700 loss 0.01128\n",
            "03/19/2025 02:40:39 - INFO - __main__ -   epoch 9 step 4800 loss 0.01505\n",
            "03/19/2025 02:41:23 - INFO - __main__ -   epoch 9 step 4900 loss 0.01526\n",
            "03/19/2025 02:42:07 - INFO - __main__ -   epoch 9 step 5000 loss 0.02455\n",
            "03/19/2025 02:42:51 - INFO - __main__ -   epoch 9 step 5100 loss 0.01422\n",
            "03/19/2025 02:43:35 - INFO - __main__ -   epoch 9 step 5200 loss 0.01821\n",
            "03/19/2025 02:44:19 - INFO - __main__ -   epoch 9 step 5300 loss 0.01218\n",
            "03/19/2025 02:45:04 - INFO - __main__ -   epoch 9 step 5400 loss 0.02456\n",
            "03/19/2025 02:45:48 - INFO - __main__ -   epoch 9 step 5500 loss 0.03428\n",
            "03/19/2025 02:46:32 - INFO - __main__ -   epoch 9 step 5600 loss 0.01793\n",
            "03/19/2025 02:47:16 - INFO - __main__ -   epoch 9 step 5700 loss 0.01613\n",
            "03/19/2025 02:48:00 - INFO - __main__ -   epoch 9 step 5800 loss 0.01035\n",
            "03/19/2025 02:48:44 - INFO - __main__ -   epoch 9 step 5900 loss 0.01372\n",
            "03/19/2025 02:49:28 - INFO - __main__ -   epoch 9 step 6000 loss 0.0247\n",
            "03/19/2025 02:50:12 - INFO - __main__ -   epoch 9 step 6100 loss 0.00947\n",
            "03/19/2025 02:50:57 - INFO - __main__ -   epoch 9 step 6200 loss 0.01193\n",
            "03/19/2025 02:51:41 - INFO - __main__ -   epoch 9 step 6300 loss 0.01657\n",
            "03/19/2025 02:52:25 - INFO - __main__ -   epoch 9 step 6400 loss 0.01875\n",
            "03/19/2025 02:53:09 - INFO - __main__ -   epoch 9 step 6500 loss 0.01446\n",
            "03/19/2025 02:53:53 - INFO - __main__ -   epoch 9 step 6600 loss 0.01619\n",
            "03/19/2025 02:54:37 - INFO - __main__ -   epoch 9 step 6700 loss 0.00989\n",
            "03/19/2025 02:55:21 - INFO - __main__ -   epoch 9 step 6800 loss 0.02568\n",
            "03/19/2025 02:56:06 - INFO - __main__ -   epoch 9 step 6900 loss 0.01117\n",
            "03/19/2025 02:56:50 - INFO - __main__ -   epoch 9 step 7000 loss 0.02134\n",
            "03/19/2025 02:57:34 - INFO - __main__ -   epoch 9 step 7100 loss 0.01925\n",
            "03/19/2025 02:58:18 - INFO - __main__ -   epoch 9 step 7200 loss 0.01352\n",
            "03/19/2025 02:59:02 - INFO - __main__ -   epoch 9 step 7300 loss 0.0115\n",
            "03/19/2025 02:59:46 - INFO - __main__ -   epoch 9 step 7400 loss 0.012\n",
            "03/19/2025 03:00:30 - INFO - __main__ -   epoch 9 step 7500 loss 0.01496\n",
            "03/19/2025 03:01:14 - INFO - __main__ -   epoch 9 step 7600 loss 0.01398\n",
            "03/19/2025 03:01:59 - INFO - __main__ -   epoch 9 step 7700 loss 0.01711\n",
            "03/19/2025 03:02:43 - INFO - __main__ -   epoch 9 step 7800 loss 0.0193\n",
            "03/19/2025 03:03:59 - INFO - __main__ -   ***** Running evaluation *****\n",
            "03/19/2025 03:03:59 - INFO - __main__ -     Num queries = 13914\n",
            "03/19/2025 03:03:59 - INFO - __main__ -     Num codes = 43827\n",
            "03/19/2025 03:03:59 - INFO - __main__ -     Batch size = 64\n",
            "03/19/2025 03:06:34 - INFO - __main__ -     Success@1 = 0.0\n",
            "03/19/2025 03:06:34 - INFO - __main__ -     Success@5 = 0.0001\n",
            "03/19/2025 03:06:34 - INFO - __main__ -     Success@10 = 0.0004\n",
            "03/19/2025 03:06:34 - INFO - __main__ -     MRR = 0.6531\n",
            "03/19/2025 03:06:34 - INFO - __main__ -     ********************\n",
            "03/19/2025 03:06:34 - INFO - __main__ -     Best mrr:0.6531\n",
            "03/19/2025 03:06:34 - INFO - __main__ -     ********************\n",
            "03/19/2025 03:06:37 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/CoSHC/CodeBERT/models/python/checkpoint-best-mrr/model.bin\n"
          ]
        }
      ],
      "source": [
        "LANG = \"python\"\n",
        "DATA_DIR = \"/content/data\"\n",
        "OUT_DIR = \"/content/drive/MyDrive/CoSHC/CodeBERT/models\"\n",
        "\n",
        "!python run.py \\\n",
        "    --output_dir=$OUT_DIR/$LANG \\\n",
        "    --config_name=microsoft/codebert-base \\\n",
        "    --model_name_or_path=microsoft/codebert-base \\\n",
        "    --tokenizer_name=microsoft/codebert-base \\\n",
        "    --do_train \\\n",
        "    --train_data_file=$DATA_DIR/$LANG/train.jsonl \\\n",
        "    --eval_data_file=$DATA_DIR/$LANG/valid.jsonl \\\n",
        "    --test_data_file=$DATA_DIR/$LANG/test.jsonl \\\n",
        "    --codebase_file=$DATA_DIR/$LANG/codebase.jsonl \\\n",
        "    --num_train_epochs 10 \\\n",
        "    --code_length 256 \\\n",
        "    --nl_length 128 \\\n",
        "    --train_batch_size 32 \\\n",
        "    --eval_batch_size 64 \\\n",
        "    --learning_rate 1e-5 \\\n",
        "    --max_grad_norm 1.0 \\\n",
        "    --seed 123456"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0W6hvyvvLVgS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQrjOtOoLVeF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKExgYnCLVW1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "jjkjAszqrmY8",
        "outputId": "a2d5fd6d-94b3-4570-80c3-76b66e4428d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file '/content/apex/run_classifier.py': [Errno 2] No such file or directory\n",
            "/bin/bash: line 4: --task_name: command not found\n"
          ]
        },
        {
          "ename": "CalledProcessError",
          "evalue": "Command 'python run_classifier.py \\\n  --model_type roberta \\\n  --model_name_or_path codebert-base \\  # for loading checkpoint later\n  --task_name codesearch \\\n  --do_train \\\n  --do_eval \\\n  --eval_all_checkpoints \\\n  --train_file train.txt \\\n  --dev_file valid.txt \\\n  --max_seq_length 100 \\\n  --per_gpu_train_batch_size 128 \\\n  --per_gpu_eval_batch_size 128 \\\n  --learning_rate 1e-5 \\\n  --num_train_epochs 10 \\\n  --gradient_accumulation_steps 2 \\\n  --overwrite_output_dir \\\n  --data_dir /content/drive/MyDrive/CoSHC/data/train_valid/python \\\n  --output_dir /content/drive/MyDrive/CoSHC/CodeBERT/models/python\n' returned non-zero exit status 127.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-eddc0647ee0c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'python run_classifier.py \\\\\\n  --model_type roberta \\\\\\n  --model_name_or_path codebert-base \\\\  # for loading checkpoint later\\n  --task_name codesearch \\\\\\n  --do_train \\\\\\n  --do_eval \\\\\\n  --eval_all_checkpoints \\\\\\n  --train_file train.txt \\\\\\n  --dev_file valid.txt \\\\\\n  --max_seq_length 100 \\\\\\n  --per_gpu_train_batch_size 128 \\\\\\n  --per_gpu_eval_batch_size 128 \\\\\\n  --learning_rate 1e-5 \\\\\\n  --num_train_epochs 10 \\\\\\n  --gradient_accumulation_steps 2 \\\\\\n  --overwrite_output_dir \\\\\\n  --data_dir /content/drive/MyDrive/CoSHC/data/train_valid/python \\\\\\n  --output_dir /content/drive/MyDrive/CoSHC/CodeBERT/models/python\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0mreturncode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       )\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'python run_classifier.py \\\n  --model_type roberta \\\n  --model_name_or_path codebert-base \\  # for loading checkpoint later\n  --task_name codesearch \\\n  --do_train \\\n  --do_eval \\\n  --eval_all_checkpoints \\\n  --train_file train.txt \\\n  --dev_file valid.txt \\\n  --max_seq_length 100 \\\n  --per_gpu_train_batch_size 128 \\\n  --per_gpu_eval_batch_size 128 \\\n  --learning_rate 1e-5 \\\n  --num_train_epochs 10 \\\n  --gradient_accumulation_steps 2 \\\n  --overwrite_output_dir \\\n  --data_dir /content/drive/MyDrive/CoSHC/data/train_valid/python \\\n  --output_dir /content/drive/MyDrive/CoSHC/CodeBERT/models/python\n' returned non-zero exit status 127."
          ]
        }
      ],
      "source": [
        "%%shell\n",
        "python run_classifier.py \\\n",
        "  --model_type roberta \\\n",
        "  --model_name_or_path codebert-base \\  # for loading checkpoint later\n",
        "  --task_name codesearch \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --eval_all_checkpoints \\\n",
        "  --train_file train.txt \\\n",
        "  --dev_file valid.txt \\\n",
        "  --max_seq_length 100 \\\n",
        "  --per_gpu_train_batch_size 128 \\\n",
        "  --per_gpu_eval_batch_size 128 \\\n",
        "  --learning_rate 1e-5 \\\n",
        "  --num_train_epochs 10 \\\n",
        "  --gradient_accumulation_steps 2 \\\n",
        "  --overwrite_output_dir \\\n",
        "  --data_dir /content/drive/MyDrive/CoSHC/data/train_valid/python \\\n",
        "  --output_dir /content/drive/MyDrive/CoSHC/CodeBERT/models/python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6btQMTii3f3y"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "python run_classifier.py \\\n",
        "--model_type roberta \\\n",
        "--task_name codesearch \\\n",
        "--do_train \\\n",
        "--do_eval \\\n",
        "--eval_all_checkpoints \\\n",
        "--train_file train.txt \\\n",
        "--dev_file valid.txt \\\n",
        "--max_seq_length 200 \\\n",
        "--per_gpu_train_batch_size 128 \\\n",
        "--per_gpu_eval_batch_size 128 \\\n",
        "--learning_rate 1e-5 \\\n",
        "--num_train_epochs 10 \\\n",
        "--gradient_accumulation_steps 2 \\\n",
        "--overwrite_output_dir \\\n",
        "--data_dir /content/drive/MyDrive/CoSHC/data/train_valid/python \\\n",
        "--output_dir /content/drive/MyDrive/CoSHC/CodeBERT/models/python  \\\n",
        "--model_name_or_path microsoft/codebert-base \\\n",
        "--num_examples 100000\n",
        "# --fp16 \\\n",
        "# --fp16_opt_level O1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frAf1IrLxB3O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KUIfqp-yL1x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTZuvpGPyLkN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEszK-dZyLVu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YayZFS_FVWUT",
        "outputId": "fe63a28f-a6c8-4b04-d9c3-1be2ffa0b9bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Mon Mar 10 01:40:59 2025] IPv6: ADDRCONF(NETDEV_CHANGE): br0: link becomes ready\n",
            "[Mon Mar 10 01:40:59 2025] br0: port 2(veth3380a8a) entered disabled state\n",
            "[Mon Mar 10 01:40:59 2025] eth0: renamed from veth607b52c\n",
            "[Mon Mar 10 01:40:59 2025] IPv6: ADDRCONF(NETDEV_CHANGE): vethc59e238: link becomes ready\n",
            "[Mon Mar 10 01:40:59 2025] docker0: port 1(vethc59e238) entered blocking state\n",
            "[Mon Mar 10 01:40:59 2025] docker0: port 1(vethc59e238) entered forwarding state\n",
            "[Mon Mar 10 01:40:59 2025] IPv6: ADDRCONF(NETDEV_CHANGE): docker0: link becomes ready\n",
            "[Mon Mar 10 01:41:00 2025] eth0: renamed from vethfe281ec\n",
            "[Mon Mar 10 01:41:00 2025] eth0: renamed from veth4b76337\n",
            "[Mon Mar 10 01:41:00 2025] IPv6: ADDRCONF(NETDEV_CHANGE): veth3380a8a: link becomes ready\n",
            "[Mon Mar 10 01:41:00 2025] br0: port 2(veth3380a8a) entered blocking state\n",
            "[Mon Mar 10 01:41:00 2025] br0: port 2(veth3380a8a) entered forwarding state\n",
            "[Mon Mar 10 01:41:00 2025] IPv6: ADDRCONF(NETDEV_CHANGE): veth892c34e: link becomes ready\n",
            "[Mon Mar 10 01:41:00 2025] br0: port 1(veth892c34e) entered blocking state\n",
            "[Mon Mar 10 01:41:00 2025] br0: port 1(veth892c34e) entered forwarding state\n",
            "[Mon Mar 10 01:41:21 2025] br0: port 1(veth892c34e) entered disabled state\n",
            "[Mon Mar 10 01:41:21 2025] vethfe281ec: renamed from eth0\n",
            "[Mon Mar 10 01:41:21 2025] br0: port 1(veth892c34e) entered disabled state\n",
            "[Mon Mar 10 01:41:21 2025] device veth892c34e left promiscuous mode\n",
            "[Mon Mar 10 01:41:21 2025] br0: port 1(veth892c34e) entered disabled state\n",
            "[Mon Mar 10 01:42:09 2025] docker0: port 2(veth36f0ec5) entered blocking state\n",
            "[Mon Mar 10 01:42:09 2025] docker0: port 2(veth36f0ec5) entered disabled state\n",
            "[Mon Mar 10 01:42:09 2025] device veth36f0ec5 entered promiscuous mode\n",
            "[Mon Mar 10 01:42:09 2025] eth0: renamed from veth62331c1\n",
            "[Mon Mar 10 01:42:09 2025] IPv6: ADDRCONF(NETDEV_CHANGE): veth36f0ec5: link becomes ready\n",
            "[Mon Mar 10 01:42:10 2025] docker0: port 2(veth36f0ec5) entered blocking state\n",
            "[Mon Mar 10 01:42:10 2025] docker0: port 2(veth36f0ec5) entered forwarding state\n",
            "[Mon Mar 10 01:55:08 2025] python3 invoked oom-killer: gfp_mask=0xcc0(GFP_KERNEL), order=0, oom_score_adj=0\n",
            "[Mon Mar 10 01:55:08 2025] CPU: 0 PID: 45634 Comm: python3 Tainted: P           OE      6.1.85+ #1\n",
            "[Mon Mar 10 01:55:08 2025] Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 02/12/2025\n",
            "[Mon Mar 10 01:55:08 2025] Call Trace:\n",
            "[Mon Mar 10 01:55:08 2025]  <TASK>\n",
            "[Mon Mar 10 01:55:08 2025]  dump_stack_lvl+0x4a/0x70\n",
            "[Mon Mar 10 01:55:08 2025]  dump_header+0x52/0x250\n",
            "[Mon Mar 10 01:55:08 2025]  oom_kill_process+0x10a/0x220\n",
            "[Mon Mar 10 01:55:08 2025]  out_of_memory+0x3dc/0x5c0\n",
            "[Mon Mar 10 01:55:08 2025]  ? mem_cgroup_iter+0x1a0/0x240\n",
            "[Mon Mar 10 01:55:08 2025]  try_charge_memcg+0x827/0xa90\n",
            "[Mon Mar 10 01:55:08 2025]  charge_memcg+0x3f/0x1f0\n",
            "[Mon Mar 10 01:55:08 2025]  __mem_cgroup_charge+0x2b/0x80\n",
            "[Mon Mar 10 01:55:08 2025]  handle_mm_fault+0xf80/0x16b0\n",
            "[Mon Mar 10 01:55:08 2025]  do_user_addr_fault+0x271/0x4d0\n",
            "[Mon Mar 10 01:55:08 2025]  exc_page_fault+0x78/0xf0\n",
            "[Mon Mar 10 01:55:08 2025]  asm_exc_page_fault+0x22/0x30\n",
            "[Mon Mar 10 01:55:08 2025] RIP: 0033:0x7a74be4ed8b0\n",
            "[Mon Mar 10 01:55:08 2025] Code: 48 89 73 60 4c 8d 48 10 0f 95 c1 4c 29 ea 0f b6 c9 48 83 ca 01 48 c1 e1 02 4c 09 e9 48 83 c9 01 48 89 48 08 8b 05 4c cc 17 00 <48> 89 56 08 85 c0 0f 84 ba f7 ff ff e9 44 fb ff ff 48 8d 3d 58 a4\n",
            "[Mon Mar 10 01:55:08 2025] RSP: 002b:00007ffd22677af0 EFLAGS: 00010202\n",
            "[Mon Mar 10 01:55:08 2025] RAX: 0000000000000000 RBX: 00007a74be663c80 RCX: 0000000000000651\n",
            "[Mon Mar 10 01:55:08 2025] RDX: 0000000000002d61 RSI: 00000001782c42a0 RDI: 0000000000000002\n",
            "[Mon Mar 10 01:55:08 2025] RBP: 0000000000000640 R08: 0000000000000640 R09: 00000001782c3c60\n",
            "[Mon Mar 10 01:55:08 2025] R10: 0000000000000077 R11: 00007a74be663ce0 R12: ffffffffffffffb8\n",
            "[Mon Mar 10 01:55:08 2025] R13: 0000000000000650 R14: 0000000000000065 R15: 0000000000000063\n",
            "[Mon Mar 10 01:55:08 2025]  </TASK>\n",
            "[Mon Mar 10 01:55:08 2025] memory: usage 11918336kB, limit 11918336kB, failcnt 15273\n",
            "[Mon Mar 10 01:55:08 2025] swap: usage 0kB, limit 9007199254740988kB, failcnt 0\n",
            "[Mon Mar 10 01:55:08 2025] Memory cgroup stats for /jupyter-children:\n",
            "[Mon Mar 10 01:55:08 2025] anon 12091424768\n",
            "[Mon Mar 10 01:55:08 2025] file 10502144\n",
            "[Mon Mar 10 01:55:08 2025] kernel 102424576\n",
            "[Mon Mar 10 01:55:08 2025] kernel_stack 1818624\n",
            "[Mon Mar 10 01:55:08 2025] pagetables 28745728\n",
            "[Mon Mar 10 01:55:08 2025] sec_pagetables 0\n",
            "[Mon Mar 10 01:55:08 2025] percpu 0\n",
            "[Mon Mar 10 01:55:08 2025] sock 24576\n",
            "[Mon Mar 10 01:55:08 2025] vmalloc 0\n",
            "[Mon Mar 10 01:55:08 2025] shmem 10485760\n",
            "[Mon Mar 10 01:55:08 2025] file_mapped 10489856\n",
            "[Mon Mar 10 01:55:08 2025] file_dirty 0\n",
            "[Mon Mar 10 01:55:08 2025] file_writeback 0\n",
            "[Mon Mar 10 01:55:08 2025] swapcached 0\n",
            "[Mon Mar 10 01:55:08 2025] anon_thp 0\n",
            "[Mon Mar 10 01:55:08 2025] file_thp 0\n",
            "[Mon Mar 10 01:55:08 2025] shmem_thp 0\n",
            "[Mon Mar 10 01:55:08 2025] inactive_anon 12101836800\n",
            "[Mon Mar 10 01:55:08 2025] active_anon 65536\n",
            "[Mon Mar 10 01:55:08 2025] inactive_file 8192\n",
            "[Mon Mar 10 01:55:08 2025] active_file 4096\n",
            "[Mon Mar 10 01:55:08 2025] unevictable 12288\n",
            "[Mon Mar 10 01:55:08 2025] slab_reclaimable 69757096\n",
            "[Mon Mar 10 01:55:08 2025] slab_unreclaimable 1750960\n",
            "[Mon Mar 10 01:55:08 2025] slab 71508056\n",
            "[Mon Mar 10 01:55:08 2025] workingset_refault_anon 0\n",
            "[Mon Mar 10 01:55:08 2025] workingset_refault_file 901551\n",
            "[Mon Mar 10 01:55:08 2025] workingset_activate_anon 0\n",
            "[Mon Mar 10 01:55:08 2025] Tasks state (memory values in pages):\n",
            "[Mon Mar 10 01:55:08 2025] [  pid  ]   uid  tgid total_vm      rss pgtables_bytes swapents oom_score_adj name\n",
            "[Mon Mar 10 01:55:08 2025] [   2282]     0  2282   298066    23784   475136        0             0 python3\n",
            "[Mon Mar 10 01:55:08 2025] [   2399]     0  2399   136265     4577   155648        0             0 python3\n",
            "[Mon Mar 10 01:55:08 2025] [   2420]     0  2420   310202     1505   126976        0          1000 language_servic\n",
            "[Mon Mar 10 01:55:09 2025] [   2434]     0  2434   152485     6045   811008        0          1000 node\n",
            "[Mon Mar 10 01:55:09 2025] [   3073]     0  3073     1091       69    45056        0             0 bash\n",
            "[Mon Mar 10 01:55:09 2025] [   3074]     0  3074   814535     2423   274432        0             0 drive\n",
            "[Mon Mar 10 01:55:09 2025] [   3075]     0  3075      908      325    49152        0             0 grep\n",
            "[Mon Mar 10 01:55:09 2025] [   3236]     0  3236   944567    46439  1232896        0             0 drive\n",
            "[Mon Mar 10 01:55:09 2025] [   3531]     0  3531     1091      700    49152        0             0 bash\n",
            "[Mon Mar 10 01:55:09 2025] [   3532]     0  3532   307106      332    90112        0             0 directoryprefet\n",
            "[Mon Mar 10 01:55:09 2025] [   3533]     0  3533      706      245    45056        0             0 tail\n",
            "[Mon Mar 10 01:55:09 2025] [   3534]     0  3534     5221     2497    77824        0             0 python3\n",
            "[Mon Mar 10 01:55:09 2025] [  45634]     0 45634  5775025  2908035 26484736        0             0 python3\n",
            "[Mon Mar 10 01:55:09 2025] oom-kill:constraint=CONSTRAINT_MEMCG,nodemask=(null),cpuset=jupyter-children,mems_allowed=0,oom_memcg=/jupyter-children,task_memcg=/jupyter-children,task=node,pid=2434,uid=0\n",
            "[Mon Mar 10 01:55:09 2025] Memory cgroup out of memory: Killed process 2434 (node) total-vm:609940kB, anon-rss:22416kB, file-rss:1764kB, shmem-rss:0kB, UID:0 pgtables:792kB oom_score_adj:1000\n",
            "[Mon Mar 10 01:55:10 2025] python3 invoked oom-killer: gfp_mask=0xcc0(GFP_KERNEL), order=0, oom_score_adj=0\n",
            "[Mon Mar 10 01:55:10 2025] CPU: 0 PID: 45634 Comm: python3 Tainted: P           OE      6.1.85+ #1\n",
            "[Mon Mar 10 01:55:10 2025] Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 02/12/2025\n",
            "[Mon Mar 10 01:55:10 2025] Call Trace:\n",
            "[Mon Mar 10 01:55:10 2025]  <TASK>\n",
            "[Mon Mar 10 01:55:10 2025]  dump_stack_lvl+0x4a/0x70\n",
            "[Mon Mar 10 01:55:10 2025]  dump_header+0x52/0x250\n",
            "[Mon Mar 10 01:55:10 2025]  oom_kill_process+0x10a/0x220\n",
            "[Mon Mar 10 01:55:10 2025]  out_of_memory+0x3dc/0x5c0\n",
            "[Mon Mar 10 01:55:10 2025]  ? mem_cgroup_iter+0x1a0/0x240\n",
            "[Mon Mar 10 01:55:10 2025]  try_charge_memcg+0x827/0xa90\n",
            "[Mon Mar 10 01:55:10 2025]  charge_memcg+0x3f/0x1f0\n",
            "[Mon Mar 10 01:55:10 2025]  __mem_cgroup_charge+0x2b/0x80\n",
            "[Mon Mar 10 01:55:10 2025]  handle_mm_fault+0xf80/0x16b0\n",
            "[Mon Mar 10 01:55:10 2025]  do_user_addr_fault+0x271/0x4d0\n",
            "[Mon Mar 10 01:55:10 2025]  exc_page_fault+0x78/0xf0\n",
            "[Mon Mar 10 01:55:10 2025]  asm_exc_page_fault+0x22/0x30\n",
            "[Mon Mar 10 01:55:10 2025] RIP: 0033:0x51617b\n",
            "[Mon Mar 10 01:55:10 2025] Code: 41 5c c3 49 89 dc 4c 2b 25 aa 38 59 00 4c 8b 4b 08 49 ba ab aa aa aa aa aa aa aa 49 c1 fc 04 4d 0f af e2 4d 8d 99 00 40 00 00 <41> c7 41 24 ff ff 00 00 45 89 61 20 4c 89 5b 08 89 73 10 85 f6 0f\n",
            "[Mon Mar 10 01:55:10 2025] RSP: 002b:00007ffd22677d30 EFLAGS: 00010a07\n",
            "[Mon Mar 10 01:55:10 2025] RAX: 000000000000003c RBX: 0000000104c6cdf0 RCX: 000000000000003c\n",
            "[Mon Mar 10 01:55:10 2025] RDX: 0000000040007bea RSI: 000000000000003b RDI: 000000000000003b\n",
            "[Mon Mar 10 01:55:10 2025] RBP: 0000000000000001 R08: 00007a73d7b00050 R09: 00007a71b6568000\n",
            "[Mon Mar 10 01:55:10 2025] R10: aaaaaaaaaaaaaaab R11: 00007a71b656c000 R12: 0000000000000b50\n",
            "[Mon Mar 10 01:55:10 2025] R13: 00007a73745e9a90 R14: 0000000000a43a40 R15: 000000000000000a\n",
            "[Mon Mar 10 01:55:10 2025]  </TASK>\n",
            "[Mon Mar 10 01:55:10 2025] memory: usage 11918340kB, limit 11918336kB, failcnt 62419\n",
            "[Mon Mar 10 01:55:10 2025] swap: usage 0kB, limit 9007199254740988kB, failcnt 0\n",
            "[Mon Mar 10 01:55:10 2025] Memory cgroup stats for /jupyter-children:\n",
            "[Mon Mar 10 01:55:10 2025] anon 12091445248\n",
            "[Mon Mar 10 01:55:10 2025] file 10752000\n",
            "[Mon Mar 10 01:55:10 2025] kernel 102162432\n",
            "[Mon Mar 10 01:55:10 2025] kernel_stack 1818624\n",
            "[Mon Mar 10 01:55:10 2025] pagetables 28569600\n",
            "[Mon Mar 10 01:55:10 2025] sec_pagetables 0\n",
            "[Mon Mar 10 01:55:10 2025] percpu 0\n",
            "[Mon Mar 10 01:55:10 2025] sock 20480\n",
            "[Mon Mar 10 01:55:10 2025] vmalloc 0\n",
            "[Mon Mar 10 01:55:10 2025] shmem 10485760\n",
            "[Mon Mar 10 01:55:10 2025] file_mapped 10489856\n",
            "[Mon Mar 10 01:55:10 2025] file_dirty 0\n",
            "[Mon Mar 10 01:55:10 2025] file_writeback 0\n",
            "[Mon Mar 10 01:55:10 2025] swapcached 0\n",
            "[Mon Mar 10 01:55:10 2025] anon_thp 0\n",
            "[Mon Mar 10 01:55:10 2025] file_thp 0\n",
            "[Mon Mar 10 01:55:10 2025] shmem_thp 0\n",
            "[Mon Mar 10 01:55:10 2025] inactive_anon 12101857280\n",
            "[Mon Mar 10 01:55:10 2025] active_anon 65536\n",
            "[Mon Mar 10 01:55:10 2025] inactive_file 262144\n",
            "[Mon Mar 10 01:55:10 2025] active_file 0\n",
            "[Mon Mar 10 01:55:10 2025] unevictable 12288\n",
            "[Mon Mar 10 01:55:10 2025] slab_reclaimable 69758256\n",
            "[Mon Mar 10 01:55:10 2025] slab_unreclaimable 1739688\n",
            "[Mon Mar 10 01:55:10 2025] slab 71497944\n",
            "[Mon Mar 10 01:55:10 2025] workingset_refault_anon 0\n",
            "[Mon Mar 10 01:55:10 2025] workingset_refault_file 944717\n",
            "[Mon Mar 10 01:55:10 2025] workingset_activate_anon 0\n",
            "[Mon Mar 10 01:55:10 2025] Tasks state (memory values in pages):\n",
            "[Mon Mar 10 01:55:10 2025] [  pid  ]   uid  tgid total_vm      rss pgtables_bytes swapents oom_score_adj name\n",
            "[Mon Mar 10 01:55:10 2025] [   2282]     0  2282   298066    23383   475136        0             0 python3\n",
            "[Mon Mar 10 01:55:10 2025] [   2399]     0  2399   136265     4297   155648        0             0 python3\n",
            "[Mon Mar 10 01:55:10 2025] [   2420]     0  2420   310202     2041   126976        0          1000 language_servic\n",
            "[Mon Mar 10 01:55:10 2025] [   3073]     0  3073     1091       69    45056        0             0 bash\n",
            "[Mon Mar 10 01:55:10 2025] [   3074]     0  3074   814535     2210   274432        0             0 drive\n",
            "[Mon Mar 10 01:55:10 2025] [   3075]     0  3075      908      200    49152        0             0 grep\n",
            "[Mon Mar 10 01:55:10 2025] [   3236]     0  3236   944567    46516  1232896        0             0 drive\n",
            "[Mon Mar 10 01:55:10 2025] [   3531]     0  3531     1091      506    49152        0             0 bash\n",
            "[Mon Mar 10 01:55:10 2025] [   3532]     0  3532   307106      332    90112        0             0 directoryprefet\n",
            "[Mon Mar 10 01:55:10 2025] [   3533]     0  3533      706      152    45056        0             0 tail\n",
            "[Mon Mar 10 01:55:10 2025] [   3534]     0  3534     5221     2282    77824        0             0 python3\n",
            "[Mon Mar 10 01:55:10 2025] [  45634]     0 45634  5776296  2907770 26492928        0             0 python3\n",
            "[Mon Mar 10 01:55:10 2025] oom-kill:constraint=CONSTRAINT_MEMCG,nodemask=(null),cpuset=jupyter-children,mems_allowed=0,oom_memcg=/jupyter-children,task_memcg=/jupyter-children,task=language_servic,pid=2420,uid=0\n",
            "[Mon Mar 10 01:55:10 2025] Memory cgroup out of memory: Killed process 2420 (language_servic) total-vm:1240808kB, anon-rss:6288kB, file-rss:1880kB, shmem-rss:0kB, UID:0 pgtables:124kB oom_score_adj:1000\n",
            "[Mon Mar 10 01:55:10 2025] kworker/u4:0 invoked oom-killer: gfp_mask=0xc00(GFP_NOIO), order=0, oom_score_adj=0\n",
            "[Mon Mar 10 01:55:10 2025] CPU: 0 PID: 9 Comm: kworker/u4:0 Tainted: P           OE      6.1.85+ #1\n",
            "[Mon Mar 10 01:55:10 2025] Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 02/12/2025\n",
            "[Mon Mar 10 01:55:10 2025] Workqueue: loop0 loop_workfn\n",
            "[Mon Mar 10 01:55:10 2025] Call Trace:\n",
            "[Mon Mar 10 01:55:10 2025]  <TASK>\n",
            "[Mon Mar 10 01:55:10 2025]  dump_stack_lvl+0x4a/0x70\n",
            "[Mon Mar 10 01:55:10 2025]  dump_header+0x52/0x250\n",
            "[Mon Mar 10 01:55:10 2025]  oom_kill_process+0x10a/0x220\n",
            "[Mon Mar 10 01:55:10 2025]  out_of_memory+0x3dc/0x5c0\n",
            "[Mon Mar 10 01:55:10 2025]  ? mem_cgroup_iter+0x1a0/0x240\n",
            "[Mon Mar 10 01:55:10 2025]  try_charge_memcg+0x827/0xa90\n",
            "[Mon Mar 10 01:55:10 2025]  charge_memcg+0x3f/0x1f0\n",
            "[Mon Mar 10 01:55:10 2025]  __mem_cgroup_charge+0x2b/0x80\n",
            "[Mon Mar 10 01:55:10 2025]  __filemap_add_folio+0x31a/0x3c0\n",
            "[Mon Mar 10 01:55:10 2025]  ? workingset_activation+0x150/0x150\n",
            "[Mon Mar 10 01:55:10 2025]  filemap_read+0x43f/0xb90\n",
            "[Mon Mar 10 01:55:10 2025]  ? update_load_avg+0x1e8/0x720\n",
            "[Mon Mar 10 01:55:10 2025]  do_iter_read+0x1d9/0x2e0\n",
            "[Mon Mar 10 01:55:10 2025]  loop_process_work+0x46c/0x950\n",
            "[Mon Mar 10 01:55:10 2025]  process_one_work+0x1ef/0x350\n",
            "[Mon Mar 10 01:55:10 2025]  worker_thread+0x24f/0x400\n",
            "[Mon Mar 10 01:55:10 2025]  kthread+0xed/0x110\n",
            "[Mon Mar 10 01:55:10 2025]  ? worker_clr_flags+0x50/0x50\n",
            "[Mon Mar 10 01:55:10 2025]  ? kthread_blkcg+0x40/0x40\n",
            "[Mon Mar 10 01:55:10 2025]  ret_from_fork+0x1f/0x30\n",
            "[Mon Mar 10 01:55:10 2025]  </TASK>\n",
            "[Mon Mar 10 01:55:10 2025] memory: usage 11918336kB, limit 11918336kB, failcnt 64766\n",
            "[Mon Mar 10 01:55:10 2025] swap: usage 0kB, limit 9007199254740988kB, failcnt 0\n",
            "[Mon Mar 10 01:55:10 2025] Memory cgroup stats for /jupyter-children:\n",
            "[Mon Mar 10 01:55:10 2025] anon 12091469824\n",
            "[Mon Mar 10 01:55:10 2025] file 10747904\n",
            "[Mon Mar 10 01:55:10 2025] kernel 102137856\n",
            "[Mon Mar 10 01:55:10 2025] kernel_stack 1802240\n",
            "[Mon Mar 10 01:55:10 2025] pagetables 28569600\n",
            "[Mon Mar 10 01:55:10 2025] sec_pagetables 0\n",
            "[Mon Mar 10 01:55:10 2025] percpu 0\n",
            "[Mon Mar 10 01:55:10 2025] sock 20480\n",
            "[Mon Mar 10 01:55:10 2025] vmalloc 0\n",
            "[Mon Mar 10 01:55:10 2025] shmem 10485760\n",
            "[Mon Mar 10 01:55:10 2025] file_mapped 10489856\n",
            "[Mon Mar 10 01:55:10 2025] file_dirty 0\n",
            "[Mon Mar 10 01:55:10 2025] file_writeback 0\n",
            "[Mon Mar 10 01:55:10 2025] swapcached 0\n",
            "[Mon Mar 10 01:55:10 2025] anon_thp 0\n",
            "[Mon Mar 10 01:55:10 2025] file_thp 0\n",
            "[Mon Mar 10 01:55:10 2025] shmem_thp 0\n",
            "[Mon Mar 10 01:55:10 2025] inactive_anon 12101881856\n",
            "[Mon Mar 10 01:55:10 2025] active_anon 65536\n",
            "[Mon Mar 10 01:55:10 2025] inactive_file 258048\n",
            "[Mon Mar 10 01:55:10 2025] active_file 0\n",
            "[Mon Mar 10 01:55:10 2025] unevictable 12288\n",
            "[Mon Mar 10 01:55:10 2025] slab_reclaimable 69757944\n",
            "[Mon Mar 10 01:55:10 2025] slab_unreclaimable 1739600\n",
            "[Mon Mar 10 01:55:10 2025] slab 71497544\n",
            "[Mon Mar 10 01:55:10 2025] workingset_refault_anon 0\n",
            "[Mon Mar 10 01:55:10 2025] workingset_refault_file 945128\n",
            "[Mon Mar 10 01:55:10 2025] workingset_activate_anon 0\n",
            "[Mon Mar 10 01:55:11 2025] Tasks state (memory values in pages):\n",
            "[Mon Mar 10 01:55:11 2025] [  pid  ]   uid  tgid total_vm      rss pgtables_bytes swapents oom_score_adj name\n",
            "[Mon Mar 10 01:55:11 2025] [   2282]     0  2282   298066    23321   475136        0             0 python3\n",
            "[Mon Mar 10 01:55:11 2025] [   2399]     0  2399   136265     4250   155648        0             0 python3\n",
            "[Mon Mar 10 01:55:11 2025] [   3073]     0  3073     1091       69    45056        0             0 bash\n",
            "[Mon Mar 10 01:55:11 2025] [   3074]     0  3074   814535     2200   274432        0             0 drive\n",
            "[Mon Mar 10 01:55:11 2025] [   3075]     0  3075      908      193    49152        0             0 grep\n",
            "[Mon Mar 10 01:55:11 2025] [   3236]     0  3236   944567    46516  1232896        0             0 drive\n",
            "[Mon Mar 10 01:55:11 2025] [   3531]     0  3531     1091      504    49152        0             0 bash\n",
            "[Mon Mar 10 01:55:11 2025] [   3532]     0  3532   307106      332    90112        0             0 directoryprefet\n",
            "[Mon Mar 10 01:55:11 2025] [   3533]     0  3533      706      146    45056        0             0 tail\n",
            "[Mon Mar 10 01:55:11 2025] [   3534]     0  3534     5221     2238    77824        0             0 python3\n",
            "[Mon Mar 10 01:55:11 2025] [  45634]     0 45634  5776329  2908120 26492928        0             0 python3\n",
            "[Mon Mar 10 01:55:11 2025] oom-kill:constraint=CONSTRAINT_MEMCG,nodemask=(null),cpuset=/,mems_allowed=0,oom_memcg=/jupyter-children,task_memcg=/jupyter-children,task=python3,pid=45634,uid=0\n",
            "[Mon Mar 10 01:55:11 2025] Memory cgroup out of memory: Killed process 45634 (python3) total-vm:23105316kB, anon-rss:11545020kB, file-rss:77220kB, shmem-rss:10240kB, UID:0 pgtables:25872kB oom_score_adj:0\n",
            "[Mon Mar 10 02:00:45 2025] printk: dmesg (73936): Attempt to access syslog with CAP_SYS_ADMIN but no CAP_SYSLOG (deprecated).\n",
            "[Mon Mar 10 02:08:26 2025] python3 invoked oom-killer: gfp_mask=0x100cca(GFP_HIGHUSER_MOVABLE), order=0, oom_score_adj=0\n",
            "[Mon Mar 10 02:08:26 2025] CPU: 1 PID: 2440 Comm: python3 Tainted: P           OE      6.1.85+ #1\n",
            "[Mon Mar 10 02:08:26 2025] Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 02/12/2025\n",
            "[Mon Mar 10 02:08:26 2025] Call Trace:\n",
            "[Mon Mar 10 02:08:26 2025]  <TASK>\n",
            "[Mon Mar 10 02:08:26 2025]  dump_stack_lvl+0x4a/0x70\n",
            "[Mon Mar 10 02:08:26 2025]  dump_header+0x52/0x250\n",
            "[Mon Mar 10 02:08:26 2025]  oom_kill_process+0x10a/0x220\n",
            "[Mon Mar 10 02:08:26 2025]  out_of_memory+0x3dc/0x5c0\n",
            "[Mon Mar 10 02:08:26 2025]  ? mem_cgroup_iter+0x1a0/0x240\n",
            "[Mon Mar 10 02:08:26 2025]  try_charge_memcg+0x827/0xa90\n",
            "[Mon Mar 10 02:08:26 2025]  charge_memcg+0x3f/0x1f0\n",
            "[Mon Mar 10 02:08:26 2025]  __mem_cgroup_charge+0x2b/0x80\n",
            "[Mon Mar 10 02:08:26 2025]  __filemap_add_folio+0x31a/0x3c0\n",
            "[Mon Mar 10 02:08:26 2025]  ? workingset_activation+0x150/0x150\n",
            "[Mon Mar 10 02:08:26 2025]  __filemap_get_folio+0x27a/0x360\n",
            "[Mon Mar 10 02:08:26 2025]  filemap_fault+0x212/0x510\n",
            "[Mon Mar 10 02:08:26 2025]  ? filemap_map_pages+0x204/0x6c0\n",
            "[Mon Mar 10 02:08:26 2025]  __do_fault+0x4a/0x110\n",
            "[Mon Mar 10 02:08:26 2025]  handle_mm_fault+0x980/0x16b0\n",
            "[Mon Mar 10 02:08:26 2025]  do_user_addr_fault+0x271/0x4d0\n",
            "[Mon Mar 10 02:08:26 2025]  exc_page_fault+0x78/0xf0\n",
            "[Mon Mar 10 02:08:26 2025]  asm_exc_page_fault+0x22/0x30\n",
            "[Mon Mar 10 02:08:26 2025] RIP: 0033:0x56c14f\n",
            "[Mon Mar 10 02:08:26 2025] Code: 45 89 f7 48 89 6c 24 30 b8 ff ff ff 7f 41 89 c9 4c 89 6c 24 40 41 89 c5 44 89 64 24 2c 4d 89 c4 48 8b 54 24 58 41 89 de 89 dd <44> 0f b6 02 41 80 f8 7c 0f 85 eb 01 00 00 41 81 fd ff ff ff 7f 0f\n",
            "[Mon Mar 10 02:08:26 2025] RSP: 002b:00007fa2dcc6f540 EFLAGS: 00010246\n",
            "[Mon Mar 10 02:08:26 2025] RAX: 000000007fffffff RBX: 0000000000000000 RCX: 0000000000000000\n",
            "[Mon Mar 10 02:08:26 2025] RDX: 0000000000737c48 RSI: 000000000000003a RDI: 0000000000a4ee38\n",
            "[Mon Mar 10 02:08:26 2025] RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000\n",
            "[Mon Mar 10 02:08:26 2025] R10: 00007fa2dcc6f920 R11: 000000000053d751 R12: 0000000000000000\n",
            "[Mon Mar 10 02:08:26 2025] R13: 000000007fffffff R14: 0000000000000000 R15: 0000000000000000\n",
            "[Mon Mar 10 02:08:26 2025]  </TASK>\n",
            "[Mon Mar 10 02:08:26 2025] memory: usage 11918336kB, limit 11918336kB, failcnt 93305\n",
            "[Mon Mar 10 02:08:26 2025] swap: usage 0kB, limit 9007199254740988kB, failcnt 0\n",
            "[Mon Mar 10 02:08:26 2025] Memory cgroup stats for /jupyter-children:\n",
            "[Mon Mar 10 02:08:26 2025] anon 12086190080\n",
            "[Mon Mar 10 02:08:26 2025] file 10854400\n",
            "[Mon Mar 10 02:08:26 2025] kernel 107315200\n",
            "[Mon Mar 10 02:08:26 2025] kernel_stack 1818624\n",
            "[Mon Mar 10 02:08:26 2025] pagetables 29138944\n",
            "[Mon Mar 10 02:08:26 2025] sec_pagetables 0\n",
            "[Mon Mar 10 02:08:26 2025] percpu 0\n",
            "[Mon Mar 10 02:08:26 2025] sock 20480\n",
            "[Mon Mar 10 02:08:26 2025] vmalloc 0\n",
            "[Mon Mar 10 02:08:26 2025] shmem 10485760\n",
            "[Mon Mar 10 02:08:26 2025] file_mapped 10489856\n",
            "[Mon Mar 10 02:08:26 2025] file_dirty 0\n",
            "[Mon Mar 10 02:08:26 2025] file_writeback 0\n",
            "[Mon Mar 10 02:08:26 2025] swapcached 0\n",
            "[Mon Mar 10 02:08:26 2025] anon_thp 0\n",
            "[Mon Mar 10 02:08:26 2025] file_thp 0\n",
            "[Mon Mar 10 02:08:26 2025] shmem_thp 0\n",
            "[Mon Mar 10 02:08:26 2025] inactive_anon 12096602112\n",
            "[Mon Mar 10 02:08:26 2025] active_anon 65536\n",
            "[Mon Mar 10 02:08:26 2025] inactive_file 356352\n",
            "[Mon Mar 10 02:08:26 2025] active_file 8192\n",
            "[Mon Mar 10 02:08:26 2025] unevictable 12288\n",
            "[Mon Mar 10 02:08:26 2025] slab_reclaimable 74203296\n",
            "[Mon Mar 10 02:08:26 2025] slab_unreclaimable 1885896\n",
            "[Mon Mar 10 02:08:26 2025] slab 76089192\n",
            "[Mon Mar 10 02:08:26 2025] workingset_refault_anon 0\n",
            "[Mon Mar 10 02:08:26 2025] workingset_refault_file 2792309\n",
            "[Mon Mar 10 02:08:26 2025] workingset_activate_anon 0\n",
            "[Mon Mar 10 02:08:26 2025] Tasks state (memory values in pages):\n",
            "[Mon Mar 10 02:08:26 2025] [  pid  ]   uid  tgid total_vm      rss pgtables_bytes swapents oom_score_adj name\n",
            "[Mon Mar 10 02:08:26 2025] [   2282]     0  2282   367408    51913   987136        0             0 python3\n",
            "[Mon Mar 10 02:08:26 2025] [   2399]     0  2399   136265     4295   155648        0             0 python3\n",
            "[Mon Mar 10 02:08:26 2025] [   3073]     0  3073     1091       69    45056        0             0 bash\n",
            "[Mon Mar 10 02:08:26 2025] [   3074]     0  3074   814535     2148   274432        0             0 drive\n",
            "[Mon Mar 10 02:08:26 2025] [   3075]     0  3075      908      171    49152        0             0 grep\n",
            "[Mon Mar 10 02:08:26 2025] [   3236]     0  3236   938420    11219  1228800        0             0 drive\n",
            "[Mon Mar 10 02:08:26 2025] [   3531]     0  3531     1091      504    49152        0             0 bash\n",
            "[Mon Mar 10 02:08:26 2025] [   3532]     0  3532   307266      354    98304        0             0 directoryprefet\n",
            "[Mon Mar 10 02:08:26 2025] [   3533]     0  3533      706      142    45056        0             0 tail\n",
            "[Mon Mar 10 02:08:26 2025] [   3534]     0  3534     5221     2143    77824        0             0 python3\n",
            "[Mon Mar 10 02:08:26 2025] [  94170]     0 94170  5773710  2916621 26546176        0             0 python3\n",
            "[Mon Mar 10 02:08:26 2025] oom-kill:constraint=CONSTRAINT_MEMCG,nodemask=(null),cpuset=jupyter-children,mems_allowed=0,oom_memcg=/jupyter-children,task_memcg=/jupyter-children,task=python3,pid=94170,uid=0\n",
            "[Mon Mar 10 02:08:26 2025] Memory cgroup out of memory: Killed process 94170 (python3) total-vm:23094840kB, anon-rss:11577296kB, file-rss:78948kB, shmem-rss:10240kB, UID:0 pgtables:25924kB oom_score_adj:0\n"
          ]
        }
      ],
      "source": [
        "!dmesg -T | grep -E -i -B100 \"killed process\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSjesGImxl_U",
        "outputId": "8b23bcaa-073f-4ed4-e3f6-aa29ff7732f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Mar 10 02:00:36 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vsh7cFOPyFZi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}